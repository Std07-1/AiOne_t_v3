# stage1/binance_future_asset_filter.py

"""
–°—É–ø–µ—Ä—à–≤–∏–¥–∫–∏–π —Ñ—ñ–ª—å—Ç—Ä USDT‚ÄëM‚Äë—Ñ'—é—á–µ—Ä—Å—ñ–≤ Binance –∑ —Ä–æ–∑—à–∏—Ä–µ–Ω–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
–ì–æ–ª–æ–≤–Ω—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ
* –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∏–π –∑–±—ñ—Ä –¥–∞–Ω–∏—Ö –∑ –æ–±–º–µ–∂–µ–Ω–Ω—è–º —Å–µ–º–∞—Ñ–æ—Ä—ñ–≤
* –î–∏–Ω–∞–º—ñ—á–Ω—ñ –ø–æ—Ä–æ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—ñ–≤
* –ö–µ—à—É–≤–∞–Ω–Ω—è exchangeInfo —É Redis (3 –≥–æ–¥)
* Pydantic –≤–∞–ª—ñ–¥–∞—Ü—ñ—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
* –î–µ—Ç–∞–ª—å–Ω–µ –ª–æ–≥—É–≤–∞–Ω–Ω—è —Ç–∞ –æ–±—Ä–æ–±–∫–∞ –ø–æ–º–∏–ª–æ–∫
* –†–∞–Ω–∂—É–≤–∞–Ω–Ω—è –∑–∞ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–º liquidity_score
* –ú–∏—Ç—Ç—î–≤–∞ –æ–±—Ä–æ–±–∫–∞ –¥–æ 500+ —Å–∏–º–≤–æ–ª—ñ–≤
–í–∏—Ö—ñ–¥: –≤—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω–∏–π —Å–ø–∏—Å–æ–∫ —Ç—ñ–∫–µ—Ä—ñ–≤, –≥–æ—Ç–æ–≤–∏–π –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ—ó –æ–±—Ä–æ–±–∫–∏
"""

import logging
import time
from typing import List, Union

import aiohttp
import asyncio
import pandas as pd

from stage1.config import SymbolInfo, FilterParams
from stage1.utils import format_open_interest, format_volume_usd

from stage1.helpers import (
    _fetch_json,
    fetch_cached_data,
    fetch_open_interest,
    fetch_orderbook_depth,
    fetch_atr,
    fetch_concurrently,
)
from stage1.config import (
    OI_SEMAPHORE,
    KLINES_SEMAPHORE,
    DEPTH_SEMAPHORE,
)

from rich.progress import (
    Progress,
    SpinnerColumn,
    BarColumn,
    TextColumn,
    TimeElapsedColumn,
    MofNCompleteColumn,
    TaskProgressColumn,
)

from stage1.visualization import print_results
from stage1.config import MetricResults

from rich.console import Console
from rich.logging import RichHandler

# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è ---
logger = logging.getLogger("binance_future_asset_filter")
logger.setLevel(logging.INFO)
logger.handlers.clear()
logger.addHandler(RichHandler(console=Console(stderr=True), show_path=False))
logger.propagate = False

# –ì–ª–æ–±–∞–ª—å–Ω–∏–π –∫–æ–Ω—Å–æ–ª—å –¥–ª—è –∑—Ä—É—á–Ω–æ—Å—Ç—ñ
console = Console()


# CORE LOGIC
class BinanceFutureAssetFilter:
    def __init__(self, session: aiohttp.ClientSession, cache_handler):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Ñ—ñ–ª—å—Ç—Ä–∞ –∞–∫—Ç–∏–≤—ñ–≤ Binance Futures.
        :param session: aiohttp.ClientSession –¥–ª—è HTTP-–∑–∞–ø–∏—Ç—ñ–≤
        :param cache_handler: –æ–±—Ä–æ–±–Ω–∏–∫ –∫–µ—à—É (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, Redis)
        """
        self.session = session
        self.cache_handler = cache_handler
        self.metrics = {}
        self.progress = None
        self.metrics_progress = None  # –î–æ–¥–∞—Ç–∫–æ–≤–∏–π –∞—Ç—Ä–∏–±—É—Ç –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—É –º–µ—Ç—Ä–∏–∫
        logger.debug("BinanceFutureAssetFilter —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ")

    async def load_exchange_info(self) -> List[SymbolInfo]:
        """
        –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ —Å–∏–º–≤–æ–ª–∏ –∑ –∫–µ—à—É –∞–±–æ API Binance.
        –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ SymbolInfo –¥–ª—è USDT-PERPETUAL TRADING —Å–∏–º–≤–æ–ª—ñ–≤.
        """
        logger.debug("[STEP] –ü–æ—á–∞—Ç–æ–∫ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è exchangeInfo")

        def process_data(data: Union[dict, list]) -> List[dict]:
            # –û–±—Ä–æ–±–∫–∞ —Ä—ñ–∑–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç—ñ–≤ –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö
            logger.debug(f"[EVENT] –û–±—Ä–æ–±–∫–∞ exchangeInfo, —Ç–∏–ø: {type(data)}")
            symbols = data.get("symbols", []) if isinstance(data, dict) else data
            filtered = [
                s
                for s in symbols
                if s.get("quoteAsset") == "USDT"
                and s.get("status") == "TRADING"
                and s.get("contractType") == "PERPETUAL"
            ]
            logger.debug(
                f"[EVENT] –í—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(filtered)} —Å–∏–º–≤–æ–ª—ñ–≤ –∑ exchangeInfo"
            )
            return filtered

        data = await fetch_cached_data(
            self.session,
            self.cache_handler,
            "binance_futures_exchange_info",
            "https://fapi.binance.com/fapi/v1/exchangeInfo",
            process_data,
        )
        logger.debug(f"[STEP] –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ exchangeInfo, –∫—ñ–ª—å–∫—ñ—Å—Ç—å: {len(data)}")
        return [SymbolInfo(**s) for s in data]

    async def fetch_ticker_data(self) -> pd.DataFrame:
        """
        –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö 24h ticker –∑ Binance Futures API.
        –ü–æ–≤–µ—Ä—Ç–∞—î DataFrame –∑ –¥–∞–Ω–∏–º–∏ –ø–æ –≤—Å—ñ—Ö —Å–∏–º–≤–æ–ª–∞—Ö.
        """
        url = "https://fapi.binance.com/fapi/v1/ticker/24hr"
        logger.debug(f"[STEP] –ó–∞–ø–∏—Ç ticker/24hr: {url}")
        try:
            data = await _fetch_json(self.session, url)
            logger.debug(f"[EVENT] –û—Ç—Ä–∏–º–∞–Ω–æ {len(data)} –∑–∞–ø–∏—Å—ñ–≤ ticker")
            return pd.DataFrame(data)
        except Exception as e:
            logger.error("–ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è ticker –¥–∞–Ω–∏—Ö: %s", e)
            return pd.DataFrame()

    async def apply_dynamic_thresholds(
        self, df: pd.DataFrame, params: FilterParams
    ) -> FilterParams:
        """
        –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –¥–∏–Ω–∞–º—ñ—á–Ω–∏—Ö –ø–æ—Ä–æ–≥—ñ–≤ –¥–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó –∞–∫—Ç–∏–≤—ñ–≤ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—ñ–≤.
        –û–Ω–æ–≤–ª—é—î params –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ –¥–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ quoteVolume —Ç–∞ priceChangePercent.
        """
        logger.debug("[STEP] –ü–æ—á–∞—Ç–æ–∫ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –¥–∏–Ω–∞–º—ñ—á–Ω–∏—Ö –ø–æ—Ä–æ–≥—ñ–≤")
        try:
            df = df.copy()
            df["quoteVolume"] = pd.to_numeric(df["quoteVolume"], errors="coerce")
            df["priceChangePercent"] = pd.to_numeric(
                df["priceChangePercent"], errors="coerce"
            ).abs()
            logger.debug(f"[EVENT] –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–æ —Ç–∏–ø–∏, –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø–∏—Å—ñ–≤: {len(df)}")

            df = df.dropna(subset=["quoteVolume", "priceChangePercent"])
            logger.debug(f"[EVENT] –ü—ñ—Å–ª—è dropna: {len(df)} –∑–∞–ø–∏—Å—ñ–≤")

            if len(df) > 10:
                params.min_quote_volume = df["quoteVolume"].quantile(0.75)
                params.min_price_change = df["priceChangePercent"].quantile(0.70)
                logger.info(
                    "–î–∏–Ω–∞–º—ñ—á–Ω—ñ –ø–æ—Ä–æ–≥–∏: Vol ‚â• %.2f, Œî%% ‚â• %.2f",
                    params.min_quote_volume,
                    params.min_price_change,
                )
                logger.debug(
                    f"[EVENT] –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ—Ä–æ–≥–∏: min_quote_volume={params.min_quote_volume}, min_price_change={params.min_price_change}"
                )
            else:
                logger.debug("[EVENT] –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è –¥–∏–Ω–∞–º—ñ—á–Ω–∏—Ö –ø–æ—Ä–æ–≥—ñ–≤")
            return params
        except Exception as e:
            logger.error("–ü–æ–º–∏–ª–∫–∞ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –¥–∏–Ω–∞–º—ñ—á–Ω–∏—Ö –ø–æ—Ä–æ–≥—ñ–≤: %s", e)
            return params

    async def filter_assets(self, params: FilterParams) -> List[str]:
        """
        –û—Å–Ω–æ–≤–Ω–∏–π –ø–∞–π–ø–ª–∞–π–Ω —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó –∞–∫—Ç–∏–≤—ñ–≤ Binance Futures.
        –í–∏–∫–æ–Ω—É—î –≤—Å—ñ –µ—Ç–∞–ø–∏: –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è, —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è, –∑–±—ñ—Ä –º–µ—Ç—Ä–∏–∫, —Ä–∞–Ω–∂—É–≤–∞–Ω–Ω—è.
        –ü–æ–≤–µ—Ä—Ç–∞—î –≤—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω–∏–π —Å–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª—ñ–≤.
        """
        start_time = time.monotonic()
        console.print("üîç [bold cyan]–ü–æ—á–∞—Ç–æ–∫ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó –∞–∫—Ç–∏–≤—ñ–≤...[/bold cyan]")

        # –°—Ç–≤–æ—Ä—é—î–º–æ —î–¥–∏–Ω–∏–π –ø—Ä–æ–≥—Ä–µ—Å-–±–∞—Ä –∑ —Ä–æ–∑—à–∏—Ä–µ–Ω–∏–º–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è–º–∏
        self.progress = Progress(
            SpinnerColumn("dots", style="bold cyan"),
            BarColumn(
                bar_width=40,
                complete_style="bold rgb(0,200,0)",
                finished_style="bold green",
                pulse_style="bold yellow",
            ),
            TaskProgressColumn(
                text_format="[bold]{task.percentage:>3.0f}%[/bold]", style="bold white"
            ),
            TextColumn("‚Ä¢", style="dim"),
            MofNCompleteColumn(),
            TextColumn("‚Ä¢", style="dim"),
            TextColumn("[bold]{task.description}", style="bold white"),
            TextColumn("‚Ä¢", style="dim"),
            TimeElapsedColumn(),
            console=Console(stderr=True),
            transient=False,
            refresh_per_second=20,
        )
        self.progress.start()

        # –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –µ—Ç–∞–ø—ñ–≤
        total_steps = 9
        main_task = self.progress.add_task("–§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∞–∫—Ç–∏–≤—ñ–≤...", total=total_steps)

        # –ö—Ä–æ–∫ 1: –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –±–∞–∑–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
        logger.debug("[STEP] –ö—Ä–æ–∫ 1: –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è exchangeInfo")
        self.progress.update(main_task, description="[cyan]üîç –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö...")
        exchange_info = await self.load_exchange_info()
        valid_symbols = {s.symbol for s in exchange_info}
        logger.debug(f"[EVENT] –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(valid_symbols)} –≤–∞–ª—ñ–¥–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤")

        self.progress.advance(main_task)

        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è ticker –¥–∞–Ω–∏—Ö
        self.progress.update(
            main_task, description="[cyan]üìä –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö —Ç–∏–∫–µ—Ä–∞..."
        )
        ticker_df = await self.fetch_ticker_data()
        logger.debug(f"[EVENT] –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ ticker_df, shape: {ticker_df.shape}")
        if ticker_df.empty:
            logger.error("–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –¥–∞–Ω—ñ ticker")
            return []

        self.progress.advance(main_task)  # –ü—Ä–æ—Å—É–≤–∞—î–º–æ –ø—Ä–æ–≥—Ä–µ—Å

        # –ö—Ä–æ–∫ 2: –î–∏–Ω–∞–º—ñ—á–Ω—ñ –ø–æ—Ä–æ–≥–∏ (—è–∫—â–æ –∞–∫—Ç–∏–≤–æ–≤–∞–Ω–æ)
        self.progress.update(main_task, description="[cyan]‚öôÔ∏è –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –ø–æ—Ä–æ–≥—ñ–≤...")
        logger.debug("[STEP] –ö—Ä–æ–∫ 2: –î–∏–Ω–∞–º—ñ—á–Ω—ñ –ø–æ—Ä–æ–≥–∏")
        if params.dynamic:
            params = await self.apply_dynamic_thresholds(ticker_df, params)
            logger.debug(f"[EVENT] –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –ø—ñ—Å–ª—è –¥–∏–Ω–∞–º—ñ–∫–∏: {params.dict()}")
        else:
            logger.debug("[EVENT] –î–∏–Ω–∞–º—ñ—á–Ω—ñ –ø–æ—Ä–æ–≥–∏ –≤–∏–º–∫–Ω–µ–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Å—Ç–∞—Ç–∏—á–Ω—ñ")

        self.progress.advance(main_task)

        # –ö—Ä–æ–∫ 3: –ë–∞–∑–æ–≤–∏–π —Ñ—ñ–ª—å—Ç—Ä
        logger.debug("[STEP] –ö—Ä–æ–∫ 3: –ë–∞–∑–æ–≤–∏–π —Ñ—ñ–ª—å—Ç—Ä")
        self.progress.update(main_task, description="[cyan]‚öôÔ∏è –ë–∞–∑–æ–≤–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è...")
        ticker_df = ticker_df[ticker_df["symbol"].isin(valid_symbols)].copy()
        ticker_df["quoteVolume"] = pd.to_numeric(
            ticker_df["quoteVolume"], errors="coerce"
        )
        ticker_df["priceChangePercent"] = pd.to_numeric(
            ticker_df["priceChangePercent"], errors="coerce"
        ).abs()
        logger.debug(f"[EVENT] –ü—ñ—Å–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó –ø–æ symbol: {ticker_df.shape}")

        base_mask = (ticker_df["quoteVolume"] >= params.min_quote_volume) & (
            ticker_df["priceChangePercent"] >= params.min_price_change
        )
        prefiltered_df = ticker_df[base_mask].copy()
        logger.debug(f"[EVENT] –ü—ñ—Å–ª—è –±–∞–∑–æ–≤–æ–≥–æ –º–∞—Å–∫—É: {prefiltered_df.shape}")

        if prefiltered_df.empty:
            logger.warning("–ù–µ–º–∞—î –∞–∫—Ç–∏–≤—ñ–≤ –ø—ñ—Å–ª—è –±–∞–∑–æ–≤–æ—ó —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó")
            return []

        symbols = prefiltered_df["symbol"].tolist()
        logger.debug("–ü—ñ—Å–ª—è –±–∞–∑–æ–≤–æ—ó —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó: %d –∞–∫—Ç–∏–≤—ñ–≤", len(symbols))
        # –õ–æ–≥—É–≤–∞–Ω–Ω—è —Å–∏–º–≤–æ–ª—ñ–≤ –¥–ª—è –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫
        logger.debug(f"[EVENT] –°–∏–º–≤–æ–ª–∏ –¥–ª—è –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫: {symbols}")

        self.progress.advance(main_task)

        # –ö—Ä–æ–∫ 4: –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∏–π –∑–±—ñ—Ä –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫
        logger.debug("[STEP] –ö—Ä–æ–∫ 4: –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∏–π –∑–±—ñ—Ä openInterest")
        self.progress.update(main_task, description="[cyan]üìà –ó–±—ñ—Ä –º–µ—Ç—Ä–∏–∫...")

        # –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–≤–¥–∞–Ω–Ω—è –¥–ª—è –º–µ—Ç—Ä–∏–∫ —Ç—ñ–ª—å–∫–∏ –∑–∞—Ä–∞–∑, –∫–æ–ª–∏ –∑–Ω–∞—î–º–æ symbols
        total_metrics = len(symbols) * 3
        metrics_task = self.progress.add_task(
            "[bold yellow] OI ‚Ä¢ Depth ‚Ä¢ ATR[/bold yellow]", total=total_metrics
        )

        # –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∏–π –∑–±—ñ—Ä openInterest
        oi_data = await fetch_concurrently(
            self.session,
            symbols,
            fetch_open_interest,
            OI_SEMAPHORE,
            progress_callback=lambda: self.progress.advance(metrics_task),
        )
        logger.debug(f"[EVENT] –ó—ñ–±—Ä–∞–Ω–æ openInterest –¥–ª—è {len(oi_data)} —Å–∏–º–≤–æ–ª—ñ–≤")

        logger.debug("[STEP] –ö—Ä–æ–∫ 4: –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∏–π –∑–±—ñ—Ä orderbookDepth")

        # –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∏–π –∑–±—ñ—Ä orderbookDepth
        depth_data = await fetch_concurrently(
            self.session,
            symbols,
            fetch_orderbook_depth,
            DEPTH_SEMAPHORE,
            progress_callback=lambda: self.progress.advance(metrics_task),
        )
        logger.debug(f"[EVENT] –ó—ñ–±—Ä–∞–Ω–æ orderbookDepth –¥–ª—è {len(depth_data)} —Å–∏–º–≤–æ–ª—ñ–≤")

        logger.debug("[STEP] –ö—Ä–æ–∫ 4: –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∏–π –∑–±—ñ—Ä ATR")

        # –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∏–π –∑–±—ñ—Ä ATR
        atr_data = await fetch_concurrently(
            self.session,
            symbols,
            fetch_atr,
            KLINES_SEMAPHORE,
            progress_callback=lambda: self.progress.advance(metrics_task),
        )
        logger.debug(f"[EVENT] –ó—ñ–±—Ä–∞–Ω–æ ATR –¥–ª—è {len(atr_data)} —Å–∏–º–≤–æ–ª—ñ–≤")

        self.progress.advance(main_task)

        # –ö—Ä–æ–∫ 5: –û–Ω–æ–≤–ª–µ–Ω–Ω—è DataFrame
        logger.debug("[STEP] –ö—Ä–æ–∫ 5: –û–Ω–æ–≤–ª–µ–Ω–Ω—è DataFrame –¥–æ–¥–∞—Ç–∫–æ–≤–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏")

        self.progress.update(main_task, description="–û–Ω–æ–≤–ª–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö")
        self.progress.update(main_task, description="[cyan]üîÑ –û–Ω–æ–≤–ª–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö...")
        prefiltered_df["openInterest"] = prefiltered_df["symbol"].map(oi_data)
        prefiltered_df["orderbookDepth"] = prefiltered_df["symbol"].map(depth_data)
        prefiltered_df["atrPercent"] = prefiltered_df["symbol"].map(atr_data)
        logger.debug(
            f"[EVENT] DataFrame –ø—ñ—Å–ª—è –¥–æ–¥–∞–≤–∞–Ω–Ω—è –º–µ—Ç—Ä–∏–∫: {prefiltered_df.shape}"
        )
        self.progress.advance(main_task)

        # –õ–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –≥–ª–∏–±–∏–Ω–∏ —Å—Ç–∞–∫–∞–Ω—É —Ç–∞ open interest
        for sym in prefiltered_df["symbol"]:
            depth_val = prefiltered_df.loc[
                prefiltered_df["symbol"] == sym, "orderbookDepth"
            ].values[0]
            oi_val = prefiltered_df.loc[
                prefiltered_df["symbol"] == sym, "openInterest"
            ].values[0]
            logger.debug(
                f"[EVENT] –ì–ª–∏–±–∏–Ω–∞ —Å—Ç–∞–∫–∞–Ω—É –¥–ª—è {sym}: {format_volume_usd(depth_val)}"
            )
            logger.debug(
                f"[EVENT] Open Interest –¥–ª—è {sym}: {format_open_interest(oi_val)}"
            )
        self.progress.update(main_task, advance=1)

        # –ö—Ä–æ–∫ 6: –î–æ–¥–∞—Ç–∫–æ–≤–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è
        logger.debug(
            "[STEP] –ö—Ä–æ–∫ 6: –î–æ–¥–∞—Ç–∫–æ–≤–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –ø–æ openInterest, orderbookDepth, atrPercent"
        )
        self.progress.update(main_task, description="[cyan]‚öôÔ∏è –î–æ–¥–∞—Ç–∫–æ–≤–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è...")
        filtered_df = prefiltered_df[
            (prefiltered_df["openInterest"] >= params.min_open_interest)
            & (prefiltered_df["orderbookDepth"] >= params.min_orderbook_depth)
            & (prefiltered_df["atrPercent"] >= params.min_atr_percent)
        ].copy()
        logger.debug(f"[EVENT] –ü—ñ—Å–ª—è –¥–æ–¥–∞—Ç–∫–æ–≤–æ—ó —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó: {filtered_df.shape}")

        if filtered_df.empty:
            logger.warning("–ù–µ–º–∞—î –∞–∫—Ç–∏–≤—ñ–≤ –ø—ñ—Å–ª—è –ø–æ–≤–Ω–æ—ó —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó")
            return []
        self.progress.advance(main_task)

        # –ö—Ä–æ–∫ 7: –†–∞–Ω–∂—É–≤–∞–Ω–Ω—è –∞–∫—Ç–∏–≤—ñ–≤
        logger.debug("[STEP] –ö—Ä–æ–∫ 7: –†–∞–Ω–∂—É–≤–∞–Ω–Ω—è –∞–∫—Ç–∏–≤—ñ–≤")
        self.progress.update(main_task, description="[cyan]üèÜ –†–∞–Ω–∂—É–≤–∞–Ω–Ω—è –∞–∫—Ç–∏–≤—ñ–≤...")
        filtered_df["liquidity_score"] = (
            0.5 * filtered_df["quoteVolume"] / filtered_df["quoteVolume"].max()
            + 0.3 * filtered_df["openInterest"] / filtered_df["openInterest"].max()
            + 0.2 * filtered_df["orderbookDepth"] / filtered_df["orderbookDepth"].max()
        )
        logger.debug(f"[EVENT] –î–æ–¥–∞–Ω–æ liquidity_score, shape: {filtered_df.shape}")

        result = (
            filtered_df.sort_values("liquidity_score", ascending=False)
            .head(params.max_symbols)["symbol"]
            .tolist()
        )
        logger.debug(f"[EVENT] –í—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω–æ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π —Å–ø–∏—Å–æ–∫: {result}")
        self.progress.advance(main_task)

        # –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—è
        self.progress.update(
            main_task, description="[bold green]‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ![/bold green]"
        )

        # –ê–Ω—ñ–º–∞—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è
        for _ in range(3):
            self.progress.update(
                main_task,
                description="[blink bold green]üöÄ –£—Å–ø—ñ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ![/blink bold green]",
            )
            await asyncio.sleep(0.2)
        self.progress.stop()

        # –ö—Ä–æ–∫ 8: –û–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        elapsed = time.monotonic() - start_time

        # –°—Ç–≤–æ—Ä—é—î–º–æ –æ–±'—î–∫—Ç –º–µ—Ç—Ä–∏–∫
        metrics = MetricResults(
            initial_count=len(ticker_df),
            prefiltered_count=len(prefiltered_df),
            filtered_count=len(filtered_df),
            result_count=len(result),
            elapsed_time=elapsed,
            params=params.dict(),
        )

        # –í–∏–≤–æ–¥–∏–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        print_results(result, metrics)

        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –Ω–∞–ª–∞–≥–æ–¥–∂–µ–Ω–Ω—è
        self.metrics = metrics
        logger.debug(f"[EVENT] –ó–±–µ—Ä–µ–∂–µ–Ω–æ –º–µ—Ç—Ä–∏–∫–∏: {self.metrics}")

        return result
