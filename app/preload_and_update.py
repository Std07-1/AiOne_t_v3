"""–ü–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫ –ø–µ—Ä—ñ–æ–¥–∏—á–Ω–æ–≥–æ prefilter —Ç–∞ —ñ—Å—Ç–æ—Ä–∏—á–Ω–æ–≥–æ preload.

–®–ª—è—Ö: ``app/preload_and_update.py``

–§–æ–Ω–æ–≤—ñ –∑–∞–¥–∞—á—ñ:
    ‚Ä¢ periodic_prefilter_and_update ‚Äî –ø–µ—Ä—ñ–æ–¥–∏—á–Ω–æ –≤–∏–∫–æ–Ω—É—î Stage1 prefilter —ñ –æ–Ω–æ–≤–ª—é—î fast_symbols.
    ‚Ä¢ preload_1m_history ‚Äî –º–∞—Å–æ–≤–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –æ—Å—Ç–∞–Ω–Ω—ñ—Ö 1m –±–∞—Ä—ñ–≤ –¥–ª—è —Ö–æ–ª–æ–¥–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç—É RAM —à–∞—Ä—É.
    ‚Ä¢ preload_daily_levels ‚Äî –≤–∏–±—ñ—Ä–∫–∞ –¥–µ–Ω–Ω–∏—Ö –±–∞—Ä—ñ–≤ –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö —Ä—ñ–≤–Ω—ñ–≤ / —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫.
"""

import asyncio
import logging
import time
import uuid
from typing import Any, cast

import aiohttp
import pandas as pd
from rich.console import Console
from rich.logging import RichHandler

from config.config import (
    PREFILTER_INTERVAL_SEC,
    PRELOAD_1M_LOOKBACK_INIT,
    PRELOAD_DAILY_DAYS,
    SCREENING_LOOKBACK,
)
from data.unified_store import UnifiedDataStore
from stage1.optimized_asset_filter import get_filtered_assets

# –ù—ñ—è–∫–æ—ó –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó —á–∞—Å—É: –ø—Ä–∞—Ü—é—î–º–æ —ñ–∑ —Å–∏—Ä–∏–º–∏ timestamp –∑ Binance —è–∫ —î

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –õ–æ–≥—É–≤–∞–Ω–Ω—è ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logger = logging.getLogger("app.preload")
if not logger.handlers:
    logger.setLevel(logging.INFO)
    # show_path=True –¥–ª—è —á—ñ—Ç–∫–æ—ó –≤–∫–∞–∑—ñ–≤–∫–∏ —Ñ–∞–π–ª—É/—Ä—è–¥–∫–∞ —É WARNING/ERROR
    logger.addHandler(RichHandler(console=Console(stderr=True), show_path=True))
    logger.propagate = False


# ‚îÄ‚îÄ –§–æ–Ω–æ–≤–∏–π —Ç–∞—Å–∫: –ø–µ—Ä—ñ–æ–¥–∏—á–Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è fast_symbols —á–µ—Ä–µ–∑ prefilter ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def periodic_prefilter_and_update(
    cache,
    session: aiohttp.ClientSession,
    thresholds,
    interval: int = PREFILTER_INTERVAL_SEC,
    buffer: UnifiedDataStore | None = None,
    lookback: int = PRELOAD_1M_LOOKBACK_INIT,
):
    """
    –ü–µ—Ä—ñ–æ–¥–∏—á–Ω–æ –≤–∏–∫–æ–Ω—É—î prefilter —Ç–∞ –æ–Ω–æ–≤–ª—é—î fast_symbols —É Redis.
    –î–æ–¥–∞—î preload —ñ—Å—Ç–æ—Ä—ñ—ó –¥–ª—è –Ω–æ–≤–∏—Ö –∞–∫—Ç–∏–≤—ñ–≤.
    """
    # –ü–æ—á–∞—Ç–∫–æ–≤–∏–π –Ω–∞–±—ñ—Ä —Å–∏–º–≤–æ–ª—ñ–≤
    initial_symbols = set(await cache.get_fast_symbols())
    prev_symbols = initial_symbols.copy()
    if initial_symbols:
        try:
            await cache.set_fast_symbols(
                sorted(initial_symbols), ttl=max(interval * 2, interval + 60)
            )
            logger.debug(
                "Prefilter bootstrap: –ø—Ä–æ–¥–æ–≤–∂–µ–Ω–æ TTL —ñ—Å–Ω—É—é—á–æ–≥–æ whitelist",
                extra={
                    "count": len(initial_symbols),
                    "head": sorted(list(initial_symbols))[:3],
                },
            )
        except Exception as exc:
            logger.warning("–ù–µ –≤–¥–∞–ª–æ—Å—è –æ–Ω–æ–≤–∏—Ç–∏ TTL –ø–æ—á–∞—Ç–∫–æ–≤–æ–≥–æ whitelist: %s", exc)

    # –ó–∞—Ç—Ä–∏–º–∫–∞ –ø–µ—Ä–µ–¥ –ø–µ—Ä—à–∏–º –æ–Ω–æ–≤–ª–µ–Ω–Ω—è–º (—â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –∫–æ–Ω—Ñ–ª—ñ–∫—Ç—É –∑ –ø–µ—Ä–≤–∏–Ω–Ω–∏–º –ø—Ä–µ—Ñ—ñ–ª—å—Ç—Ä–æ–º)
    await asyncio.sleep(interval)  # –ß–µ–∫–∞—î–º–æ –∑–≤–∏—á–∞–π–Ω–∏–π —ñ–Ω—Ç–µ—Ä–≤–∞–ª (600 —Å–µ–∫)
    while True:
        batch_id = uuid.uuid4().hex[:8]
        t0 = time.perf_counter()
        try:
            logger.info(
                "üîÑ –°—Ç–∞—Ä—Ç prefilter-—Ü–∏–∫–ª—É",
                extra={
                    "batch_id": batch_id,
                    "interval_sec": interval,
                    "prev_symbols_count": len(prev_symbols),
                    "prev_head": sorted(list(prev_symbols))[:3],
                    "prev_tail": sorted(list(prev_symbols))[-3:],
                },
            )

            fast_symbols = await get_filtered_assets(
                session=session,
                cache_handler=cache,
                thresholds=thresholds,
                dynamic=True,
            )

            if fast_symbols:
                fast_symbols = [s.lower() for s in fast_symbols]
                current_symbols = set(fast_symbols)
                await cache.set_fast_symbols(
                    fast_symbols, ttl=interval * 2
                )  # TTL 1200 —Å–µ–∫

                added = sorted(list(current_symbols - prev_symbols))
                removed = sorted(list(prev_symbols - current_symbols))
                logger.info(
                    "Prefilter: –æ–Ω–æ–≤–ª–µ–Ω–æ fast_symbols",
                    extra={
                        "batch_id": batch_id,
                        "count": len(fast_symbols),
                        "head": fast_symbols[:3],
                        "tail": fast_symbols[-3:],
                        "added_count": len(added),
                        "removed_count": len(removed),
                        "added_head": added[:3],
                        "added_tail": added[-3:],
                        "removed_head": removed[:3],
                        "removed_tail": removed[-3:],
                    },
                )

                # ‚îÄ‚îÄ preload –¥–ª—è –Ω–æ–≤–∏—Ö –∞–∫—Ç–∏–≤—ñ–≤ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                if buffer is not None:
                    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –¢–Ü–õ–¨–ö–ò –Ω–æ–≤—ñ —Å–∏–º–≤–æ–ª–∏
                    new_symbols = current_symbols - prev_symbols

                    # –î–æ–¥–∞—î–º–æ debug-–ª–æ–≥ –¥–ª—è –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è —Å—Ç–∞–Ω—ñ–≤ —Å–∏–º–≤–æ–ª—ñ–≤
                    logger.debug(
                        "–°—Ç–∞–Ω —Å–∏–º–≤–æ–ª—ñ–≤",
                        extra={
                            "batch_id": batch_id,
                            "current": len(current_symbols),
                            "previous": len(prev_symbols),
                            "new": len(new_symbols),
                            "new_head": sorted(list(new_symbols))[:3],
                            "new_tail": sorted(list(new_symbols))[-3:],
                        },
                    )
                    if new_symbols:
                        new_symbols_list = sorted(list(new_symbols))
                        logger.info(
                            "Preload —ñ—Å—Ç–æ—Ä—ñ—ó –¥–ª—è –Ω–æ–≤–∏—Ö –∞–∫—Ç–∏–≤—ñ–≤",
                            extra={
                                "batch_id": batch_id,
                                "count": len(new_symbols_list),
                                "head": new_symbols_list[:3],
                                "tail": new_symbols_list[-3:],
                                "lookback": lookback,
                            },
                        )
                        await preload_1m_history(
                            new_symbols_list, buffer, lookback=lookback, session=session
                        )
                        await preload_daily_levels(
                            new_symbols_list, buffer, days=30, session=session
                        )

                # –û–Ω–æ–≤–ª—é—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ —Å–∏–º–≤–æ–ª–∏
                prev_symbols = current_symbols
            else:
                if prev_symbols:
                    logger.warning(
                        "Prefilter –ø–æ–≤–µ—Ä–Ω—É–≤ –ø–æ—Ä–æ–∂–Ω—ñ–π —Å–ø–∏—Å–æ–∫, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–π whitelist",
                        extra={
                            "batch_id": batch_id,
                            "count": len(prev_symbols),
                        },
                    )
                    await cache.set_fast_symbols(
                        sorted(prev_symbols), ttl=max(interval, interval // 2)
                    )
                else:
                    logger.debug(
                        "Prefilter –ø–æ–≤–µ—Ä–Ω—É–≤ –ø–æ—Ä–æ–∂–Ω—ñ–π —Å–ø–∏—Å–æ–∫, –∞ —ñ—Å—Ç–æ—Ä—ñ—ó whitelist –Ω–µ–º–∞—î.",
                        extra={"batch_id": batch_id},
                    )
        except Exception as e:
            logger.warning(
                "–ü–æ–º–∏–ª–∫–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è prefilter",
                extra={"batch_id": batch_id, "error": str(e)},
            )
            if prev_symbols:
                try:
                    await cache.set_fast_symbols(
                        sorted(prev_symbols), ttl=max(interval, interval // 2)
                    )
                except Exception as ttl_exc:
                    logger.warning(
                        "–ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ–¥–æ–≤–∂–∏—Ç–∏ TTL whitelist –ø—ñ—Å–ª—è –ø–æ–º–∏–ª–∫–∏ prefilter: %s",
                        ttl_exc,
                    )
        finally:
            t1 = time.perf_counter()
            logger.info(
                "‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—è prefilter-—Ü–∏–∫–ª—É",
                extra={"batch_id": batch_id, "duration_sec": round(t1 - t0, 3)},
            )

        await asyncio.sleep(interval)  # 600 —Å–µ–∫


# ‚îÄ‚îÄ Preload —ñ—Å—Ç–æ—Ä—ñ—ó –¥–ª—è Stage1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def _fetch_batch(
    symbols: list[str], interval: str, limit: int, session: aiohttp.ClientSession
) -> dict[str, pd.DataFrame]:
    """–ü–∞–∫–µ—Ç–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–ª—è –≥—Ä—É–ø–∏ —Å–∏–º–≤–æ–ª—ñ–≤ –∑ –æ–±–º–µ–∂–µ–Ω–Ω—è–º –ø–∞—Ä–∞–ª–µ–ª—ñ–∑–º—É."""
    if not symbols:
        return {}

    batch_id = uuid.uuid4().hex[:8]
    t0 = time.perf_counter()
    logger.info(
        "–°—Ç–∞—Ä—Ç –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è",
        extra={
            "batch_id": batch_id,
            "symbols": len(symbols),
            "interval": interval,
            "limit": limit,
            "head": symbols[:3],
            "tail": symbols[-3:],
        },
    )

    semaphore = asyncio.Semaphore(5)  # –û–±–º–µ–∂–µ–Ω–Ω—è –¥–ª—è –¥–µ–Ω–Ω–∏—Ö –¥–∞–Ω–∏—Ö
    results: dict[str, pd.DataFrame] = {}

    async def fetch_single(symbol: str):
        async with semaphore:
            try:
                df = await _fetch_klines(symbol, interval, limit, session)
                if df is not None and not df.empty:
                    results[symbol] = df
                    logger.debug(
                        "‚úÖ –ü–∞–∫–µ—Ç–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: –¥–∞–Ω—ñ –æ—Ç—Ä–∏–º–∞–Ω–æ",
                        extra={
                            "batch_id": batch_id,
                            "symbol": symbol,
                            "rows": len(df),
                        },
                    )
                else:
                    results[symbol] = pd.DataFrame()
                    logger.warning(
                        "‚ùå –ü–∞–∫–µ—Ç–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: –ø–æ—Ä–æ–∂–Ω—ñ –¥–∞–Ω—ñ",
                        extra={"batch_id": batch_id, "symbol": symbol},
                    )
            except Exception as e:
                results[symbol] = pd.DataFrame()
                logger.warning(
                    "–ü–æ–º–∏–ª–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è",
                    extra={"batch_id": batch_id, "symbol": symbol, "error": str(e)},
                )
            await asyncio.sleep(0.1)  # –ù–µ–≤–µ–ª–∏–∫–∞ –∑–∞—Ç—Ä–∏–º–∫–∞ –º—ñ–∂ –∑–∞–ø–∏—Ç–∞–º–∏

    tasks = [fetch_single(symbol) for symbol in symbols]
    await asyncio.gather(*tasks, return_exceptions=True)

    ok = sum(1 for df in results.values() if not df.empty)
    t1 = time.perf_counter()
    logger.info(
        "–ó–∞–≤–µ—Ä—à–µ–Ω–æ –ø–∞–∫–µ—Ç–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è",
        extra={
            "batch_id": batch_id,
            "ok": ok,
            "total": len(symbols),
            "duration_sec": round(t1 - t0, 3),
        },
    )

    return results


async def _fetch_klines(
    symbol: str,
    interval: str,
    limit: int,
    session: aiohttp.ClientSession,
    start_time: int | None = None,
    end_time: int | None = None,
) -> pd.DataFrame | None:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–µ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è klines –¥–∞–Ω–∏—Ö –∑ Binance REST API."""
    params: dict[str, str | int] = {
        "symbol": symbol.upper(),
        "interval": interval,
        "limit": min(int(limit), 1000),
    }

    if start_time is not None:
        params["startTime"] = int(start_time)
    if end_time is not None:
        params["endTime"] = int(end_time)

    url = "https://api.binance.com/api/v3/klines"

    try:
        async with session.get(
            url, params=params, timeout=aiohttp.ClientTimeout(total=10)
        ) as response:
            if response.status == 200:
                data = await response.json()

                if not data:
                    logger.warning(
                        "–ü–æ—Ä–æ–∂–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ Binance", extra={"symbol": symbol}
                    )
                    return pd.DataFrame()

                df = pd.DataFrame(
                    data,
                    columns=[
                        "open_time",
                        "open",
                        "high",
                        "low",
                        "close",
                        "volume",
                        "close_time",
                        "quote_asset_volume",
                        "trades",
                        "taker_buy_base",
                        "taker_buy_quote",
                        "ignore",
                    ],
                )

                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è —Ç–∏–ø—ñ–≤ –¥–∞–Ω–∏—Ö
                numeric_cols = [
                    "open",
                    "high",
                    "low",
                    "close",
                    "volume",
                    "quote_asset_volume",
                ]
                for col in numeric_cols:
                    df[col] = pd.to_numeric(df[col], errors="coerce")

                df["open_time"] = pd.to_numeric(df["open_time"])
                df["close_time"] = pd.to_numeric(df["close_time"])
                df["trades"] = pd.to_numeric(df["trades"])

                # –õ–æ–≥—É–≤–∞–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ —Ñ—Ä–µ–π–º—É
                if logger.isEnabledFor(logging.DEBUG):
                    try:
                        logger.debug(
                            "–ö–æ–ª–æ–Ω–∫–∏ DataFrame",
                            extra={
                                "symbol": symbol,
                                "cols": list(map(str, df.columns.tolist())),
                            },
                        )
                    except Exception:
                        pass

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ü—ñ–ª—ñ—Å–Ω–æ—Å—Ç—ñ —á–∞—Å–æ–≤–∏—Ö –º—ñ—Ç–æ–∫
                if len(df) > 1:
                    time_diff = df["open_time"].diff().iloc[1:]
                    expected_interval = _get_interval_ms(interval)
                    anomalies = time_diff[
                        abs(time_diff - expected_interval) > 1000
                    ]  # –î–æ–ø—É—Å–∫ 1 —Å–µ–∫—É–Ω–¥–∞

                    if not anomalies.empty:
                        logger.warning(
                            "–ê–Ω–æ–º–∞–ª—ñ—ó —á–∞—Å—É",
                            extra={
                                "symbol": symbol,
                                "interval": interval,
                                "first": anomalies.head(3).astype(int).tolist(),
                            },
                        )

                # –î–µ—Ç–∞–ª—å–Ω–∏–π –ª–æ–≥ —Ç—ñ–ª—å–∫–∏ –¥–ª—è DEBUG
                if logger.isEnabledFor(logging.DEBUG):
                    logger.debug(
                        "–û—Ç—Ä–∏–º–∞–Ω–æ klines",
                        extra={
                            "symbol": symbol,
                            "interval": interval,
                            "rows": len(df),
                            "ts_head": df["open_time"].head(3).astype(int).tolist(),
                            "ts_tail": df["open_time"].tail(3).astype(int).tolist(),
                        },
                    )

                return df
            else:
                txt = await response.text()
                logger.debug(
                    "HTTP –ø–æ–º–∏–ª–∫–∞ –≤—ñ–¥ Binance",
                    extra={
                        "symbol": symbol,
                        "interval": interval,
                        "status": response.status,
                        "body_head": txt[:200],
                    },
                )
                return None

    except TimeoutError:
        logger.error("–¢–∞–π–º–∞—É—Ç –∑–∞–ø–∏—Ç—É", extra={"symbol": symbol, "interval": interval})
        return None
    except Exception as e:
        logger.error(
            "–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∑–∞–ø–∏—Ç—É",
            extra={"symbol": symbol, "interval": interval, "error": str(e)},
        )
        return None


def _get_interval_ms(interval: str) -> int:
    """–ö–æ–Ω–≤–µ—Ä—Ç—É—î —ñ–Ω—Ç–µ—Ä–≤–∞–ª —É –º—ñ–ª—ñ—Å–µ–∫—É–Ω–¥–∏."""
    intervals = {
        "1m": 60000,
        "3m": 180000,
        "5m": 300000,
        "15m": 900000,
        "30m": 1800000,
        "1h": 3600000,
        "2h": 7200000,
        "4h": 14400000,
        "6h": 21600000,
        "8h": 28800000,
        "12h": 43200000,
        "1d": 86400000,
    }
    return intervals.get(interval, 60000)


async def preload_1m_history(
    fast_symbols: list[str],
    store: UnifiedDataStore,
    lookback: int = SCREENING_LOOKBACK,
    session: aiohttp.ClientSession | None = None,
) -> dict:
    """–ú–∞—Å–æ–≤–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è 1—Ö —Ö–≤–∏–ª–∏–Ω–Ω–æ—ó —ñ—Å—Ç–æ—Ä—ñ—ó –¥–ª—è —Å–ø–∏—Å–∫—É —Å–∏–º–≤–æ–ª—ñ–≤.

    Args:
        fast_symbols: –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª—ñ–≤ –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        store: UnifiedDataStore (–Ω–µ —Å–ª–æ–≤–Ω–∏–∫!)
        lookback: –ì–ª–∏–±–∏–Ω–∞ —ñ—Å—Ç–æ—Ä—ñ—ó –≤ –±–∞—Ä–∞—Ö
        session: AIOHTTP —Å–µ—Å—ñ—è (—Å—Ç–≤–æ—Ä–∏—Ç—å –Ω–æ–≤—É —è–∫—â–æ None)

    Returns:
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
    """
    if not fast_symbols:
        logger.warning("–°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª—ñ–≤ –¥–ª—è preload –ø–æ—Ä–æ–∂–Ω—ñ–π")
        return {"total": 0, "success": 0, "failed": 0, "duration": 0}

    close_session = False
    if session is None:
        session = aiohttp.ClientSession()
        close_session = True

    stats: dict[str, Any] = {
        "total": len(fast_symbols),
        "success": 0,
        "failed": 0,
        "start_time": time.time(),
        "symbols_loaded": [],
    }

    try:
        semaphore = asyncio.Semaphore(10)

        async def fetch_with_semaphore(symbol):
            async with semaphore:
                df = await _fetch_klines(symbol, "1m", lookback, session)
                if df is not None and not df.empty:
                    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π API UnifiedDataStore
                    await store.put_bars(symbol, "1m", df)
                    stats["success"] = cast(int, stats.get("success", 0)) + 1
                    stats["symbols_loaded"].append(symbol)

                    logger.debug(
                        f"‚úÖ {symbol}: {len(df)} –±–∞—Ä—ñ–≤ | "
                        f"–û—Å—Ç–∞–Ω–Ω—ñ–π: {pd.to_datetime(df['open_time'].iloc[-1], unit='ms').strftime('%H:%M:%S')}"
                    )
                    return True
                else:
                    stats["failed"] = cast(int, stats.get("failed", 0)) + 1
                    logger.warning(f"‚ùå {symbol}: –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏")
                    return False

        tasks = [fetch_with_semaphore(symbol) for symbol in fast_symbols]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        for i, result in enumerate(results):
            if isinstance(result, Exception):
                stats["failed"] = cast(int, stats.get("failed", 0)) + 1
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ —É {fast_symbols[i]}: {result}")

    finally:
        if close_session:
            await session.close()

    end_time = time.time()
    start_time_val = cast(float, stats.get("start_time", end_time))
    stats["end_time"] = end_time
    stats["duration"] = float(end_time - start_time_val)

    success = cast(int, stats.get("success", 0))
    total = cast(int, stats.get("total", 0))
    success_rate = (success / total * 100) if total > 0 else 0.0
    logger.info(
        f"üìä Preload 1m: {stats['success']}/{stats['total']} "
        f"({success_rate:.1f}%) | –ß–∞—Å: {stats['duration']:.2f}—Å"
    )

    return stats


# ‚îÄ‚îÄ Preload –¥–µ–Ω–Ω–∏—Ö –±–∞—Ä—ñ–≤ –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö —Ä—ñ–≤–Ω—ñ–≤ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def preload_daily_levels(
    fast_symbols: list[str],
    store: UnifiedDataStore,  # UnifiedDataStore —è–∫ —î–¥–∏–Ω–µ –¥–∂–µ—Ä–µ–ª–æ —ñ—Å—Ç–∏–Ω–∏
    days: int = PRELOAD_DAILY_DAYS,
    session: aiohttp.ClientSession | None = None,
) -> dict[str, pd.DataFrame]:
    """
    Preload –¥–µ–Ω–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º—É –¥–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö —Ä—ñ–≤–Ω—ñ–≤ –ø—ñ–¥—Ç—Ä–∏–º–∫–∏/–æ–ø–æ—Ä—É.
    """
    if not fast_symbols:
        logger.warning("–°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª—ñ–≤ –¥–ª—è daily preload –ø–æ—Ä–æ–∂–Ω—ñ–π")
        return {}

    if days < 30:
        logger.warning("–î–Ω—ñ–≤ (%d) –∑–∞–º–∞–ª–æ. –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –º—ñ–Ω—ñ–º—É–º 30.", days)
        days = 30

    logger.info(
        "Preload Daily: –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ %d –¥–µ–Ω–Ω–∏—Ö —Å–≤—ñ—á–æ–∫ –¥–ª—è %d —Å–∏–º–≤–æ–ª—ñ–≤",
        days,
        len(fast_symbols),
    )

    close_session = False
    if session is None:
        session = aiohttp.ClientSession()
        close_session = True

    stats: dict[str, Any] = {
        "total": len(fast_symbols),
        "success": 0,
        "failed": 0,
        "start_time": time.time(),
        "symbols_loaded": [],
    }
    out: dict[str, pd.DataFrame] = {}

    try:
        semaphore = asyncio.Semaphore(5)  # –ú–µ–Ω—à–µ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–∏—Ö –∑–∞–ø–∏—Ç—ñ–≤ –¥–ª—è daily –¥–∞–Ω–∏—Ö

        async def fetch_with_semaphore(symbol):
            async with semaphore:
                df = await _fetch_klines(symbol, "1d", days, session)
                if df is not None and not df.empty:
                    # –ó–∞–ø–∏—Å—É—î–º–æ —á–µ—Ä–µ–∑ UnifiedDataStore —Ç–∞ —á–∏—Ç–∞—î–º–æ –Ω–∞–∑–∞–¥ –¥–ª—è –ø–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è
                    await store.put_bars(symbol, "1d", df)
                    cached = await store.get_df(symbol, "1d")
                    if cached is not None and not cached.empty:
                        out[symbol] = cached
                    stats["success"] = cast(int, stats.get("success", 0)) + 1
                    stats["symbols_loaded"].append(symbol)

                    logger.debug(f"‚úÖ Daily {symbol}: {len(df)} –¥–µ–Ω–Ω–∏—Ö –±–∞—Ä—ñ–≤")
                    return True
                else:
                    stats["failed"] = cast(int, stats.get("failed", 0)) + 1
                    logger.warning(f"‚ùå Daily {symbol}: –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏")
                    return False

        tasks = [fetch_with_semaphore(symbol) for symbol in fast_symbols]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        for i, result in enumerate(results):
            if isinstance(result, Exception):
                stats["failed"] = cast(int, stats.get("failed", 0)) + 1
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ Daily —É {fast_symbols[i]}: {result}")

    finally:
        if close_session:
            await session.close()

    end_time = time.time()
    start_time_val = cast(float, stats.get("start_time", end_time))
    stats["end_time"] = end_time
    stats["duration"] = float(end_time - start_time_val)

    success = cast(int, stats.get("success", 0))
    total = cast(int, stats.get("total", 0))
    success_rate = (success / total * 100) if total > 0 else 0.0
    logger.info(
        f"üìä Preload Daily: {stats['success']}/{stats['total']} "
        f"({success_rate:.1f}%) | –ß–∞—Å: {stats['duration']:.2f}—Å"
    )

    # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –¥–µ—Ç–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ –ø–æ –∫–æ–∂–Ω–æ–º—É —Å–∏–º–≤–æ–ª—É, —è–∫ –æ—á—ñ–∫—É—î main.py
    return out
