"""–ü–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫ –ø–µ—Ä—ñ–æ–¥–∏—á–Ω–æ–≥–æ prefilter —Ç–∞ —ñ—Å—Ç–æ—Ä–∏—á–Ω–æ–≥–æ preload.

–®–ª—è—Ö: ``app/preload_and_update.py``

–§–æ–Ω–æ–≤—ñ –∑–∞–¥–∞—á—ñ:
    ‚Ä¢ periodic_prefilter_and_update ‚Äî –ø–µ—Ä—ñ–æ–¥–∏—á–Ω–æ –≤–∏–∫–æ–Ω—É—î Stage1 prefilter —ñ –æ–Ω–æ–≤–ª—é—î fast_symbols.
    ‚Ä¢ preload_1m_history ‚Äî –º–∞—Å–æ–≤–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –æ—Å—Ç–∞–Ω–Ω—ñ—Ö 1m –±–∞—Ä—ñ–≤ –¥–ª—è —Ö–æ–ª–æ–¥–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç—É RAM —à–∞—Ä—É.
    ‚Ä¢ preload_daily_levels ‚Äî –≤–∏–±—ñ—Ä–∫–∞ –¥–µ–Ω–Ω–∏—Ö –±–∞—Ä—ñ–≤ –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö —Ä—ñ–≤–Ω—ñ–≤ / —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫.
"""

import asyncio
import logging
import pandas as pd
import aiohttp
from stage1.optimized_asset_filter import get_filtered_assets
from config.config import (
    PRELOAD_1M_LOOKBACK_INIT,
    SCREENING_LOOKBACK,
    PRELOAD_DAILY_DAYS,
    PREFILTER_INTERVAL_SEC,
)

from rich.console import Console
from rich.logging import RichHandler

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –õ–æ–≥—É–≤–∞–Ω–Ω—è ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logger = logging.getLogger("app.preload")
if not logger.handlers:
    logger.setLevel(logging.INFO)
    logger.addHandler(RichHandler(console=Console(stderr=True), show_path=False))
    logger.propagate = False


# ‚îÄ‚îÄ –§–æ–Ω–æ–≤–∏–π —Ç–∞—Å–∫: –ø–µ—Ä—ñ–æ–¥–∏—á–Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è fast_symbols —á–µ—Ä–µ–∑ prefilter ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def periodic_prefilter_and_update(
    cache,
    session: aiohttp.ClientSession,
    thresholds,
    interval: int = PREFILTER_INTERVAL_SEC,
    buffer=None,
    lookback: int = PRELOAD_1M_LOOKBACK_INIT,
):
    """
    –ü–µ—Ä—ñ–æ–¥–∏—á–Ω–æ –≤–∏–∫–æ–Ω—É—î prefilter —Ç–∞ –æ–Ω–æ–≤–ª—é—î fast_symbols —É Redis.
    –î–æ–¥–∞—î preload —ñ—Å—Ç–æ—Ä—ñ—ó –¥–ª—è –Ω–æ–≤–∏—Ö –∞–∫—Ç–∏–≤—ñ–≤.
    """
    # –ü–æ—á–∞—Ç–∫–æ–≤–∏–π –Ω–∞–±—ñ—Ä —Å–∏–º–≤–æ–ª—ñ–≤
    initial_symbols = set(await cache.get_fast_symbols())
    prev_symbols = initial_symbols.copy()

    # –ó–∞—Ç—Ä–∏–º–∫–∞ –ø–µ—Ä–µ–¥ –ø–µ—Ä—à–∏–º –æ–Ω–æ–≤–ª–µ–Ω–Ω—è–º (—â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –∫–æ–Ω—Ñ–ª—ñ–∫—Ç—É –∑ –ø–µ—Ä–≤–∏–Ω–Ω–∏–º –ø—Ä–µ—Ñ—ñ–ª—å—Ç—Ä–æ–º)
    await asyncio.sleep(interval)  # –ß–µ–∫–∞—î–º–æ –∑–≤–∏—á–∞–π–Ω–∏–π —ñ–Ω—Ç–µ—Ä–≤–∞–ª (600 —Å–µ–∫)
    while True:
        try:
            logger.info("üîÑ –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Å–ø–∏—Å–∫—É fast_symbols —á–µ—Ä–µ–∑ prefilter...")
            fast_symbols = await get_filtered_assets(
                session=session,
                cache_handler=cache,
                thresholds=thresholds,
                dynamic=True,
            )

            if fast_symbols:
                fast_symbols = [s.lower() for s in fast_symbols]
                current_symbols = set(fast_symbols)
                await cache.set_fast_symbols(
                    fast_symbols, ttl=interval * 2
                )  # TTL 1200 —Å–µ–∫

                logger.info(
                    "Prefilter: %d —Å–∏–º–≤–æ–ª—ñ–≤ –∑–∞–ø–∏—Å–∞–Ω–æ —É Redis: %s",
                    len(fast_symbols),
                    fast_symbols[:5],
                )

                # ‚îÄ‚îÄ preload –¥–ª—è –Ω–æ–≤–∏—Ö –∞–∫—Ç–∏–≤—ñ–≤ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                if buffer is not None:
                    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –¢–Ü–õ–¨–ö–ò –Ω–æ–≤—ñ —Å–∏–º–≤–æ–ª–∏
                    new_symbols = current_symbols - prev_symbols

                    # –î–æ–¥–∞—î–º–æ debug-–ª–æ–≥ –¥–ª—è –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è —Å—Ç–∞–Ω—ñ–≤ —Å–∏–º–≤–æ–ª—ñ–≤
                    logger.debug(
                        f"–°—Ç–∞–Ω —Å–∏–º–≤–æ–ª—ñ–≤: "
                        f"–ü–æ—Ç–æ—á–Ω—ñ={len(current_symbols)}, "
                        f"–ü–æ–ø–µ—Ä–µ–¥–Ω—ñ={len(prev_symbols)}, "
                        f"–ù–æ–≤—ñ={len(new_symbols)}"
                    )
                    if new_symbols:
                        new_symbols_list = list(new_symbols)
                        logger.info(
                            f"Preload —ñ—Å—Ç–æ—Ä—ñ—ó –¥–ª—è {len(new_symbols_list)} –Ω–æ–≤–∏—Ö –∞–∫—Ç–∏–≤—ñ–≤"
                        )
                        await preload_1m_history(
                            new_symbols_list, buffer, lookback=lookback, session=session
                        )
                        await preload_daily_levels(
                            new_symbols_list, days=30, session=session
                        )

                # –û–Ω–æ–≤–ª—é—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ —Å–∏–º–≤–æ–ª–∏
                prev_symbols = current_symbols
            else:
                logger.warning(
                    "Prefilter –ø–æ–≤–µ—Ä–Ω—É–≤ –ø–æ—Ä–æ–∂–Ω—ñ–π —Å–ø–∏—Å–æ–∫, fast_symbols –Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–æ."
                )
        except Exception as e:
            logger.warning("–ü–æ–º–∏–ª–∫–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è prefilter: %s", e)

        await asyncio.sleep(interval)  # 600 —Å–µ–∫


# ‚îÄ‚îÄ Preload —ñ—Å—Ç–æ—Ä—ñ—ó –¥–ª—è Stage1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def _fetch_klines(
    symbol: str, interval: str, limit: int, session: aiohttp.ClientSession
):
    url = "https://fapi.binance.com/fapi/v1/klines"
    params = {"symbol": symbol.upper(), "interval": interval, "limit": limit}
    async with session.get(url, params=params, timeout=15) as resp:
        resp.raise_for_status()
        data = await resp.json()
    cols = [
        "open_time",
        "open",
        "high",
        "low",
        "close",
        "volume",
        "close_time",
        "quote_asset_volume",
        "number_of_trades",
        "taker_buy_base",
        "taker_buy_quote",
        "ignore",
    ]
    import pandas as _pd

    df = _pd.DataFrame(data, columns=cols)
    for c in [
        "open",
        "high",
        "low",
        "close",
        "volume",
        "quote_asset_volume",
        "taker_buy_base",
        "taker_buy_quote",
    ]:
        df[c] = df[c].astype(float)
    df["open_time"] = df["open_time"].astype(int)
    df["close_time"] = df["close_time"].astype(int)
    return df


async def _fetch_batch(
    symbols: list[str], interval: str, limit: int, session: aiohttp.ClientSession
):
    out: dict[str, pd.DataFrame] = {}
    # Simple sequential to avoid rate limits; can be optimized later
    for sym in symbols:
        try:
            out[sym] = await _fetch_klines(sym, interval, limit, session)
        except Exception as e:
            logger.warning("fetch klines failed %s %s", sym, e)
            out[sym] = pd.DataFrame()
            await asyncio.sleep(0.2)
    return out


async def preload_1m_history(
    fast_symbols,
    store,
    lookback: int = SCREENING_LOOKBACK,
    session: aiohttp.ClientSession | None = None,
):
    """Preload 1m history directly into UnifiedDataStore (–±–µ–∑ –∑–æ–≤–Ω—ñ—à–Ω—å–æ–≥–æ fetcher).

    –Ø–∫—â–æ –ø–µ—Ä–µ–¥–∞–Ω–æ `session`, –¥–∞–Ω—ñ —Ç—è–≥–Ω—É—Ç—å—Å—è –∑ Binance API; —ñ–Ω–∞–∫—à–µ –≤–∏–∫–æ–Ω—É—î—Ç—å—Å—è no-op.
    Returns stats dict: {symbol: {loaded:int, missing:int}} plus aggregates.
    """
    if lookback < 12:
        logger.warning(
            "lookback (%d) –¥–ª—è 1m-–±–∞—Ä—ñ–≤ –∑–∞–Ω–∞–¥—Ç–æ –º–∞–ª–∏–π. –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –º—ñ–Ω—ñ–º—É–º 12.",
            lookback,
        )
        lookback = 12

    logger.info(
        "Preload 1m: –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ %d 1m-–±–∞—Ä—ñ–≤ –¥–ª—è %d —Å–∏–º–≤–æ–ª—ñ–≤‚Ä¶",
        lookback,
        len(fast_symbols),
    )
    if session is None:
        logger.warning(
            "preload_1m_history: session not provided ‚Äî –ø—Ä–æ–ø—É—Å–∫ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è"
        )
        raw = {sym: pd.DataFrame() for sym in fast_symbols}
    else:
        raw = await _fetch_batch(fast_symbols, "1m", lookback, session)
    stats: dict[str, dict[str, int]] = {}
    for sym, df in raw.items():
        if df is None or df.empty:
            stats[sym] = {"loaded": 0, "missing": lookback}
            continue
        # Normalize to store schema (open_time/close_time)
        if "timestamp" in df.columns:
            df = df.rename(columns={"timestamp": "open_time"})
        if "close_time" not in df.columns:
            # assume 1m bars
            df["close_time"] = df["open_time"].astype("int64") + 60_000
        # Ensure ordering and tail limit
        df = df.sort_values("open_time").tail(lookback)
        try:
            await store.put_bars(sym.lower(), "1m", df)
        except Exception as e:
            logger.warning("put_bars preload failed for %s: %s", sym, e)
            stats[sym] = {"loaded": 0, "missing": lookback}
            continue
        loaded = len(df)
        stats[sym] = {"loaded": loaded, "missing": max(0, lookback - loaded)}

    total_loaded = sum(v["loaded"] for v in stats.values())
    logger.info(
        "Preload 1m –∑–∞–≤–µ—Ä—à–µ–Ω–æ: %d –±–∞—Ä—ñ–≤ –ø–æ %d —Å–∏–º–≤–æ–ª–∞—Ö (avg=%.1f)",
        total_loaded,
        len(stats),
        total_loaded / max(1, len(stats)),
    )
    stats["_aggregate"] = {
        "symbols": len(stats),
        "total_loaded": total_loaded,
        "avg_loaded": total_loaded / max(1, len(stats)),
    }
    return stats


# ‚îÄ‚îÄ Preload –¥–µ–Ω–Ω–∏—Ö –±–∞—Ä—ñ–≤ –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö —Ä—ñ–≤–Ω—ñ–≤ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def preload_daily_levels(
    fast_symbols,
    days: int = PRELOAD_DAILY_DAYS,
    session: aiohttp.ClientSession | None = None,
):
    """
    Preload –¥–µ–Ω–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º—É –¥–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö —Ä—ñ–≤–Ω—ñ–≤ –ø—ñ–¥—Ç—Ä–∏–º–∫–∏/–æ–ø–æ—Ä—É.
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î, —â–æ days >= 30.
    """
    if days < 30:
        logger.warning(
            "–ö—ñ–ª—å–∫—ñ—Å—Ç—å –¥–Ω—ñ–≤ (%d) –¥–ª—è –¥–µ–Ω–Ω–∏—Ö –±–∞—Ä—ñ–≤ –∑–∞–Ω–∞–¥—Ç–æ –º–∞–ª–∞. –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –º—ñ–Ω—ñ–º—É–º 30.",
            days,
        )
        days = 30

    logger.info(
        "Preload Daily: –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ %d –¥–µ–Ω–Ω–∏—Ö —Å–≤—ñ—á–æ–∫ –¥–ª—è %d —Å–∏–º–≤–æ–ª—ñ–≤‚Ä¶",
        days,
        len(fast_symbols),
    )
    if session is None:
        logger.warning(
            "preload_daily_levels: session not provided ‚Äî –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ –¥–∞–Ω—ñ"
        )
        daily_data = {sym: pd.DataFrame() for sym in fast_symbols}
    else:
        daily_data = await _fetch_batch(fast_symbols, "1d", days, session)
    logger.info("Preload Daily –∑–∞–≤–µ—Ä—à–µ–Ω–æ –¥–ª—è %d —Å–∏–º–≤–æ–ª—ñ–≤.", len(daily_data))
    return daily_data
