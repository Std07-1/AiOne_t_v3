"""Stage1‚ÜíStage2‚ÜíState –ø—É–±–ª—ñ—à–µ—Ä (—Ñ–æ—Ä–º—É–≤–∞–Ω–Ω—è –∞–≥—Ä–µ–≥–æ–≤–∞–Ω–æ–≥–æ —Å—Ç–∞–Ω—É –∞–∫—Ç–∏–≤—ñ–≤).

–®–ª—è—Ö: ``app/screening_producer.py``

–ü—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è:
    ‚Ä¢ –ø–µ—Ä—ñ–æ–¥–∏—á–Ω–∏–π –∑–±—ñ—Ä –¥–∞–Ω–∏—Ö —á–µ—Ä–µ–∑ UnifiedDataStore —ñ Stage1 –º–æ–Ω—ñ—Ç–æ—Ä;
    ‚Ä¢ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç–∞ —É–Ω—ñ—Ñ—ñ–∫–∞—Ü—ñ—è —Å–∏–≥–Ω–∞–ª—ñ–≤ (confidence / tp/sl / triggers);
    ‚Ä¢ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—è –ø–æ–≤–Ω–æ–≥–æ snapshot —É Redis (–∫–∞–Ω–∞–ª —ñ –∫–ª—é—á) –¥–ª—è UI;
    ‚Ä¢ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –∂–∏—Ç—Ç—î–≤–æ–≥–æ —Ü–∏–∫–ª—É —Ç—Ä–µ–π–¥—ñ–≤ —á–µ—Ä–µ–∑ Stage3 `TradeLifecycleManager`.
"""

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
import asyncio
import json  # TODO: –≤–∏–¥–∞–ª–∏—Ç–∏ —è–∫—â–æ –Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è
import logging
import time
from datetime import datetime
from typing import TYPE_CHECKING, Any, Dict, List, Optional

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Third-party ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
from rich.console import Console
from rich.logging import RichHandler

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –í–Ω—É—Ç—Ä—ñ—à–Ω—ñ –º–æ–¥—É–ª—ñ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

from config.config import (
    DEFAULT_LOOKBACK,
    DEFAULT_TIMEFRAME,
    MIN_READY_PCT,
    MAX_PARALLEL_STAGE2,
    TRADE_REFRESH_INTERVAL,
    STAGE2_STATUS,
    ASSET_STATE,
)
from stage1.asset_monitoring import AssetMonitorStage1
from stage3.trade_manager import TradeLifecycleManager
from UI.publish_full_state import publish_full_state
from utils.utils import (
    ensure_timestamp_column,
    map_reco_to_signal,
    first_not_none,
    normalize_tp_sl,
    normalize_result_types,
    create_no_data_signal,
    create_error_signal,
)
from stage2.processor import Stage2Processor
from stage2.level_manager import LevelManager
from app.utils.helper import (
    store_to_dataframe,
    resample_5m,
    estimate_atr_pct,
)
from utils.utils import get_tick_size
from .asset_state_manager import AssetStateManager

if TYPE_CHECKING:  # pragma: no cover - only for type hints
    from data.unified_store import UnifiedDataStore

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –õ–æ–≥—É–≤–∞–Ω–Ω—è ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logger = logging.getLogger("app.screening_producer")
if not logger.handlers:
    logger.setLevel(logging.INFO)
    logger.addHandler(RichHandler(console=Console(stderr=True), show_path=False))
    logger.propagate = False


async def process_asset_batch(
    symbols: list,
    monitor: AssetMonitorStage1,
    store: "UnifiedDataStore",
    timeframe: str,
    lookback: int,
    state_manager: AssetStateManager,
):
    """–û–±—Ä–æ–±–ª—è—î –±–∞—Ç—á —Å–∏–º–≤–æ–ª—ñ–≤ —á–µ—Ä–µ–∑ UnifiedDataStore.

    –û—á—ñ–∫—É—î—Ç—å—Å—è: store.get_df(symbol, interval, limit=lookback) -> DataFrame –∑ open_time.
    """
    for symbol in symbols:
        try:
            df = await store.get_df(symbol, timeframe, limit=lookback)
            if df is None or df.empty or len(df) < 5:
                state_manager.update_asset(symbol, create_no_data_signal(symbol))
                continue
            if "open_time" in df.columns and "timestamp" not in df.columns:
                df = df.rename(columns={"open_time": "timestamp"})
            df = ensure_timestamp_column(df)
            signal = await monitor.check_anomalies(symbol, df)
            normalized = normalize_result_types(signal)
            state_manager.update_asset(symbol, normalized)
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ AssetMonitor –¥–ª—è {symbol}: {str(e)}")
            state_manager.update_asset(symbol, create_error_signal(symbol, str(e)))


_map_reco_to_signal = map_reco_to_signal
_first_not_none = first_not_none
_normalize_tp_sl = normalize_tp_sl


async def process_single_stage2(
    signal: Dict[str, Any],
    processor: "Stage2Processor",
    state_manager: "AssetStateManager",
) -> None:
    """–û–±—Ä–æ–±–ª—è—î –æ–¥–∏–Ω Stage2-—Å–∏–≥–Ω–∞–ª —ñ –æ–Ω–æ–≤–ª—é—î —Å—Ç–∞–Ω –∞–∫—Ç–∏–≤—É."""
    symbol = signal["symbol"]
    try:
        state_manager.update_asset(
            symbol, {"stage2_status": STAGE2_STATUS["PROCESSING"]}
        )

        # Stage2 (QDE_core –ø—ñ–¥ –∫–∞–ø–æ—Ç–æ–º)
        result: Dict[str, Any] = await processor.process(signal)

        update: Dict[str, Any] = {
            "stage2": True,
            "stage2_status": STAGE2_STATUS["COMPLETED"],
            "last_updated": datetime.utcnow().isoformat(),
        }

        if "error" in result:
            err_text = str(result.get("error", "unknown"))
            update.update({"signal": "NONE", "hints": [f"Stage2 error: {err_text}"]})
            state_manager.update_asset(symbol, update)
            return

        market_ctx = result.get("market_context", {}) or {}
        scenario = market_ctx.get("scenario") or "UNCERTAIN"

        recommendation = result.get("recommendation")
        if not recommendation and scenario == "UNCERTAIN":
            recommendation = "WAIT"

        signal_type = _map_reco_to_signal(recommendation or "")

        risk_params = result.get("risk_parameters", {}) or {}
        tp0 = _first_not_none(risk_params.get("tp_targets"))
        sl = risk_params.get("sl_level")
        # –ü–æ—Ç–æ—á–Ω–∞ —Ü—ñ–Ω–∞ (–¥–ª—è –ª–æ–≥—ñ–∫–∏ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ ‚Äì –Ω–µ–æ–±–æ–≤'—è–∑–∫–æ–≤–∞)
        current_price = None
        try:
            current_price = signal.get("stats", {}).get("current_price")
        except Exception:
            current_price = None

        conf = result.get("confidence_metrics", {}) or {}
        composite_conf = conf.get("composite_confidence", 0.0)

        raw_narr = (result.get("narrative") or "").strip()
        hints: List[str] = []
        if raw_narr:
            hints.append(raw_narr)
            try:
                logger.info("[NARR] %s %s", symbol, raw_narr.replace("\n", " "))
            except Exception:
                logger.debug("[NARR] %s (logging failed)", symbol)

        anomaly_det = result.get("anomaly_detection")
        trigger_reasons = result.get("trigger_reasons") or market_ctx.get(
            "trigger_reasons"
        )

        update["signal"] = signal_type
        update["recommendation"] = recommendation or None
        update["scenario"] = scenario
        update["confidence"] = composite_conf
        if hints:
            update["hints"] = list(dict.fromkeys(hints))
        # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è TP/SL —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –∫–µ–π—Å—ñ–≤ —Ç–∏–ø—É TP –Ω–∏–∂—á–µ SL –¥–ª—è BUY
        norm_tp, norm_sl, swapped, note = _normalize_tp_sl(
            tp0, sl, recommendation, current_price
        )
        if norm_tp is not None:
            update["tp"] = norm_tp
        if norm_sl is not None:
            update["sl"] = norm_sl
        if swapped:
            # –¥–æ–¥–∞—î–º–æ —Å–ª—É–∂–±–æ–≤—É –ø—Ä–∏—á–∏–Ω—É, —â–æ–± –±—É–ª–æ –≤–∏–¥–Ω–æ —É UI (—è–∫—â–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –∑–∞—Ö–æ—á–µ)
            trigger_add = note or "tp_sl_swapped"
        else:
            trigger_add = None

        update["market_context"] = market_ctx or None
        update["risk_parameters"] = risk_params or None
        update["confidence_metrics"] = conf or None
        update["anomaly_detection"] = anomaly_det or None
        existing = state_manager.state.get(symbol, {}).get("trigger_reasons") or []
        extra_triggers: List[str] = []
        if trigger_add:
            extra_triggers.append(trigger_add)
        merged_triggers = list(
            dict.fromkeys(list(existing) + list(trigger_reasons or []) + extra_triggers)
        )
        if signal_type.startswith("ALERT") and not merged_triggers:
            merged_triggers = ["signal_generated"]
        update["trigger_reasons"] = merged_triggers
        if signal_type.startswith("ALERT"):
            update["state"] = ASSET_STATE["ALERT"]
        elif signal_type == "NORMAL":
            update["state"] = ASSET_STATE["NORMAL"]
        else:
            update["state"] = update.get("state") or ASSET_STATE["NO_TRADE"]
        update["narrative"] = raw_narr or None
        state_manager.update_asset(symbol, update)

    except Exception:
        logger.exception("Stage2 –ø–æ–º–∏–ª–∫–∞ –¥–ª—è %s", symbol)
        state_manager.update_asset(
            symbol,
            {
                "stage2_status": STAGE2_STATUS["ERROR"],
                "error": "Stage2 exception (–¥–∏–≤. –ª–æ–≥–∏)",
            },
        )


async def process_single_stage2_with_semaphore(
    signal: Dict[str, Any],
    processor: "Stage2Processor",
    semaphore: asyncio.Semaphore,
    state_manager: "AssetStateManager",
) -> None:
    async with semaphore:
        await process_single_stage2(signal, processor, state_manager)


async def screening_producer(
    monitor: AssetMonitorStage1,
    store: "UnifiedDataStore",
    store_fast_symbols: "UnifiedDataStore",
    assets: List[str],
    redis_conn: Any,
    trade_manager: Optional[TradeLifecycleManager] = None,
    reference_symbol: str = "BTCUSDT",
    timeframe: str = DEFAULT_TIMEFRAME,
    lookback: int = DEFAULT_LOOKBACK,
    interval_sec: int = TRADE_REFRESH_INTERVAL,
    min_ready_pct: float = MIN_READY_PCT,
    state_manager: AssetStateManager = None,
    level_manager: LevelManager = None,
    user_lang: str = "UA",
    user_style: str = "explain",
) -> None:
    logger.info(
        f"üöÄ –°—Ç–∞—Ä—Ç screening_producer: {len(assets)} –∞–∫—Ç–∏–≤—ñ–≤, —Ç–∞–π–º—Ñ—Ä–µ–π–º {timeframe}, –≥–ª–∏–±–∏–Ω–∞ {lookback}, –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –∫–æ–∂–Ω—ñ {interval_sec} —Å–µ–∫"
    )
    _last_levels_update_ts: Dict[str, int] = {}
    LEVELS_UPDATE_EVERY = 25
    if state_manager is None:
        assets_current = [s.lower() for s in (assets or [])]
        state_manager = AssetStateManager(assets_current)
    else:
        assets_current = list(state_manager.state.keys())
    for sym in assets_current:
        state_manager.init_asset(sym)
    ref = (reference_symbol or "BTCUSDT").lower()
    if ref not in state_manager.state:
        state_manager.init_asset(ref)
    logger.info(f"–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ —Å—Ç–∞–Ω –¥–ª—è {len(assets_current)} –∞–∫—Ç–∏–≤—ñ–≤")
    processor = Stage2Processor(
        timeframe=timeframe,
        state_manager=state_manager,
        level_manager=level_manager,
        user_lang=user_lang,
        user_style=user_style,
    )
    stage2_semaphore = asyncio.Semaphore(MAX_PARALLEL_STAGE2)
    await publish_full_state(state_manager, store, redis_conn)
    while True:
        start_time = time.time()
        try:
            new_assets_raw = await store_fast_symbols.get_fast_symbols()
            if new_assets_raw:
                new_assets = [s.lower() for s in new_assets_raw]
                current_set = set(assets_current)
                new_set = set(new_assets)
                added = new_set - current_set
                removed = current_set - new_set
                for symbol in added:
                    state_manager.init_asset(symbol)
                assets_current = list(new_set)
                for symbol in removed:
                    state_manager.state.pop(symbol, None)
                if added or removed:
                    logger.info(
                        f"üîÑ –û–Ω–æ–≤–ª–µ–Ω–æ —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤—ñ–≤: +{len(added)}/-{len(removed)} (–∑–∞–≥–∞–ª–æ–º: {len(assets_current)})"
                    )
            else:
                logger.debug(
                    "get_fast_symbols() –ø–æ–≤–µ—Ä–Ω—É–≤ –ø–æ—Ä–æ–∂–Ω—å–æ ‚Äî —Ç—Ä–∏–º–∞—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–π —Å–ø–∏—Å–æ–∫ (%d).",
                    len(assets_current),
                )
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –∞–∫—Ç–∏–≤—ñ–≤: {str(e)}")
        ready_assets: List[str] = []
        ref_ready = False
        for symbol in assets_current:
            try:
                df_tmp = await store.get_df(symbol, timeframe, limit=lookback)
                if df_tmp is not None and not df_tmp.empty and len(df_tmp) >= lookback:
                    ready_assets.append(symbol)
            except Exception:
                continue
        try:
            ref_df = await store.get_df(
                reference_symbol.lower(), timeframe, limit=lookback
            )
            ref_ready = bool(
                ref_df is not None and not ref_df.empty and len(ref_df) >= lookback
            )
        except Exception:
            ref_ready = False
        ready_count = len(ready_assets)
        min_ready = max(1, int(len(assets_current) * min_ready_pct))
        if ready_count < min_ready:
            logger.warning(
                f"‚è≥ –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: {ready_count}/{min_ready} –∞–∫—Ç–∏–≤—ñ–≤ –≥–æ—Ç–æ–≤—ñ. –û—á—ñ–∫—É–≤–∞–Ω–Ω—è {interval_sec} —Å–µ–∫..."
            )
            await asyncio.sleep(interval_sec)
            continue
        logger.info(
            f"üìä –î–∞–Ω—ñ –≥–æ—Ç–æ–≤—ñ –¥–ª—è {ready_count}/{len(assets_current)} –∞–∫—Ç–∏–≤—ñ–≤"
            + (" (+reference ready)" if ref_ready else "")
        )
        now_ts = int(time.time())
        for symbol in ready_assets:
            last_ts = _last_levels_update_ts.get(symbol, 0)
            if (now_ts - last_ts) < LEVELS_UPDATE_EVERY:
                continue
            df_1m = await store_to_dataframe(store, symbol, limit=500)
            if df_1m is None or df_1m.empty:
                continue
            df_5m = resample_5m(df_1m)
            atr_pct = estimate_atr_pct(df_1m)
            price_hint = float(df_1m["close"].iloc[-1])
            tick_size = get_tick_size(symbol, price_hint=price_hint)
            level_manager.update_meta(symbol, atr_pct=atr_pct, tick_size=tick_size)
            level_manager.update_from_bars(symbol, df_1m=df_1m, df_5m=df_5m)
            _last_levels_update_ts[symbol] = now_ts
        try:
            batch_size = 20
            tasks: List[asyncio.Task] = []
            for i in range(0, len(ready_assets), batch_size):
                batch = ready_assets[i : i + batch_size]
                tasks.append(
                    asyncio.create_task(
                        process_asset_batch(
                            batch, monitor, store, timeframe, lookback, state_manager
                        )
                    )
                )
            if tasks:
                await asyncio.gather(*tasks)
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ Stage1: {str(e)}")
        alert_signals = state_manager.get_alert_signals()
        if alert_signals:
            logger.info(f"[Stage2] –û–±—Ä–æ–±–∫–∞ {len(alert_signals)} —Å–∏–≥–Ω–∞–ª—ñ–≤...")
            tasks = [
                asyncio.create_task(
                    process_single_stage2_with_semaphore(
                        signal, processor, stage2_semaphore, state_manager
                    )
                )
                for signal in alert_signals
            ]
            await asyncio.gather(*tasks)
            logger.info(f"[Stage2] –ó–∞–≤–µ—Ä—à–µ–Ω–æ –æ–±—Ä–æ–±–∫—É {len(alert_signals)} —Å–∏–≥–Ω–∞–ª—ñ–≤")
        else:
            logger.info("[Stage2] –ù–µ–º–∞—î —Å–∏–≥–Ω–∞–ª—ñ–≤ ALERT –¥–ª—è –æ–±—Ä–æ–±–∫–∏")
        logger.info("üì¢ –ü—É–±–ª—ñ–∫–∞—Ü—ñ—è —Å—Ç–∞–Ω—É –∞–∫—Ç–∏–≤—ñ–≤...")
        await publish_full_state(state_manager, store, redis_conn)
        processing_time = time.time() - start_time
        # –ú–µ—Ç—Ä–∏–∫–∞ —á–∞—Å—É —Ü–∏–∫–ª—É (Prometheus —è–∫—â–æ —É–≤—ñ–º–∫–Ω–µ–Ω–æ)
        try:
            store.metrics.put_latency.labels(layer="screening_cycle").observe(
                processing_time
            )
        except Exception:
            pass
        logger.info(f"‚è≥ –ß–∞—Å –æ–±—Ä–æ–±–∫–∏ —Ü–∏–∫–ª—É: {processing_time:.2f} —Å–µ–∫")
        if processing_time < 1:
            logger.warning(
                "–ß–∞—Å –æ–±—Ä–æ–±–∫–∏ —Ü–∏–∫–ª—É –º–µ–Ω—à–µ 1 —Å–µ–∫—É–Ω–¥–∏ ‚Äî —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–∞—Ü—é—î –¥—É–∂–µ —à–≤–∏–¥–∫–æ"
            )
        sleep_time = (
            1
            if processing_time >= interval_sec
            else max(1, interval_sec - int(processing_time))
        )
        logger.info(f"‚è± –ß–∞—Å –æ—á—ñ–∫—É–≤–∞–Ω–Ω—è –¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ —Ü–∏–∫–ª—É: {sleep_time} —Å–µ–∫")
        await asyncio.sleep(sleep_time)
