# AiOne_t – Автоматизований криптотрейдинг-бот

**AiOne_t** – багаторівневий автоматизований бот для криптовалютного трейдингу.  
Система в реальному часі моніторить фбючерсний ринок, визначає аномалії та генерує торгові сигнали з рекомендаціями.  
Проєкт знаходиться в режимі **активної розробки** – можливі зміни API та логіки.

---

## ВАЖЛИВО: Правовий статус та захист

> **Copyright © 2024 Stanislav Std07-1. All rights reserved.**
>
> Проєкт, ідеї, архітектура та вихідний код є **власністю Stanislav Std07-1**.  
> Будь-яке комерційне використання, копіювання суттєвих частин коду чи присвоєння авторства заборонено без письмового дозволу власника.  
> Для ліцензійних питань, інтеграції в комерційні проекти або співпраці — звертайтесь за контактами нижче.

**Ліцензія:**  
Програмне забезпечення поширюється за умовами файлу [LICENSE](LICENSE) (Proprietary License).

---

## Про автора

- Автор та власник: [Stanislav Std07-1](https://github.com/Std07-1)
- TG: [@Std07_1](https://t.me/Std07_1)
- Email: Viktoriakievstd1@gmail.com, Stdst07.1@gmail.com

## Партнери

Проєкт спочатку розроблявся у співпраці з [Dmitriy](@yonkersss), відповідальним за налаштування алгоритмів.

---

## Розробка:

- Дата початку розробки: 14.10.2024
- Публікація на GitHub: 14.07.2025


---

## Основні функції

* **Реальний моніторинг ринків:** Підключення до стрімів біржі (напр. Binance) з читанням 1-хвилинних та 5-хвилинних свічок. Система **в режимі реального часу** обробляє потоки даних, гарантуючи мінімальну затримку при виявленні подій.

* **Тригерна система аномалій:** Вбудовані тригери Stage1 відстежують ключові **патерни та аномалії**, зокрема: сплески обсягу, різкі зміни волатильності (ATR), екстремальні значення RSI (перекупленість/перепроданість), пробиття локальних рівнів підтримки/опору, відхилення ціни від VWAP тощо. Кожен тригер сигналізує про можливу торгову ситуацію.

* **Адаптивна аналітика (Stage2):** Розширений аналіз сигналів включає **калібрування під актив** (динамічне налаштування порогів під ринковий стан конкретного символу), **контекстний аналіз ринку** (тренди, кореляції, рівні), оцінку впевненості сигналу та генерацію людино-зрозумілого нарративу. Це дозволяє врахувати ширший контекст перед винесенням рекомендації.

* **Генерація сигналів і рекомендацій:** На виході система продукує зведені **торгові сигнали** з рекомендаціями дій: наприклад, “BUY” (купувати), “WAIT” (чекати підтвердження) чи “AVOID” (уникати угоди). До кожного сигналу додаються пояснення (нарратив) та розраховані параметри ризику (рівні входу/виходу, співвідношення прибуток-ризик).

* **Кешування та швидкодія:** Для проміжного зберігання даних використовується Redis через модуль `SimpleCacheHandler`. Кеш містить оперативні метрики ринку, результати калібрування та поточний стан активів, що дає змогу прискорити доступ до налаштувань і уникнути дублювання розрахунків. **SimpleCacheHandler** надає просте API для читання/запису даних в Redis.

* **Інтерфейс користувача (UI):** Вбудований консольний UI на базі `Rich` забезпечує візуалізацію сигналів у реальному часі. Таблиця в режимі live-оновлення показує по кожному активу: статус сигналу (ALERT/NORMAL/NONE), поточні показники (ціна, ATR, RSI, обсяги), рекомендацію, рівні TakeProfit/StopLoss та ін. Також передбачена інтеграція з Telegram (через `TELEGRAM_TOKEN`) для відправки важливих сповіщень адміністраторам.

## Архітектурна структура

Система побудована модульно, розділена на кілька стадій обробки даних та допоміжні компоненти. Нижче наведено огляд архітектури та деталей реалізації кожного компонента:

### Stage1 – Моніторинг та первинні тригери аномалій

Stage1 відповідає за **швидкий аналіз стрімінгових даних** і генерацію сирих сигналів. Основні риси Stage1:

* **Моніторинг WS-барів:** Клас `AssetMonitorStage1` під’єднується до потоку свічок (наприклад, через `WSWorker`) і обробляє кожну нову 1-хвилинну свічку. Дані зберігаються у буфері (`RAMBuffer`) для швидкого доступу.
* **Аномальні тригери:** При надходженні нового бару, Stage1 перевіряє низку критеріїв аномалій:

  * **Сплеск обсягу:** порівнює поточний обсяг з середнім та стандартним відхиленням, обчислює Z-score. Якщо Z-score обсягу перевищує поріг (`vol_z_threshold`), фіксується аномально високий обсяг.
  * **RSI та динамічний RSI:** розраховується RSI (період 14). Визначається входження RSI у зони перекупленості/перепроданості (статичні пороги або динамічно скориговані множником `dynamic_rsi_multiplier`). Також відстежуються розбіжності (дивергенції) RSI як окремий тригер.
  * **Локальні рівні підтримки/опору:** обчислюються глобальні рівні (на основі денних даних) методом `calculate_global_levels`. Якщо ціна пробиває недавні екстремуми або ключові рівні – виникає сигнал про прорив (`breakout_level_trigger`).
  * **VWAP відхилення:** `vwap_deviation_trigger` перевіряє наскільки ціна відхилилася від VWAP (30-хвил. вікно) більше заданого порогу.
  * **Волатильність ATR:** порівнюється поточна волатильність (напр. ATR-канал для останніх барів) з каліброваними порогами `low_gate`/`high_gate`. Якщо ціновий рух виходить за «тихий» чи «надто волатильний» діапазон, це реєструється як аномалія.
* **Накопичення причин сигналу:** Якщо для певної свічки спрацьовує одразу декілька тригерів, Stage1 агрегує **список причин** (`trigger_reasons`). Приклад: `["VOLUME_SPIKE", "RSI_OVERSOLD"]` означає, що одночасно зафіксовано сплеск обсягу та RSI в зоні перепроданості. Кількість тригерів також впливає на важливість сигналу.
* **Вихід Stage1:** Для кожного активу формується словник зі статистикою та ознаками:

  * `symbol`: тикер активу (наприклад, `"BTCUSDT"`).
  * `signal`: тип сигналу Stage1 – зазвичай `"NORMAL"` (немає серйозної аномалії) або `"ALERT"` (виявлено вагому аномалію, що потребує перевірки Stage2). Якщо даних недостатньо, сигнал може бути `"NONE"`.
  * `trigger_reasons`: список причин, чому сигнал помічено (назви спрацювавших тригерів).
  * `stats`: словник базових метрик стану ринку:

    * `current_price` – поточна ціна активу,
    * `price_change` – зміна ціни за вибраний період,
    * `atr` – поточний ATR,
    * `rsi` – значення RSI,
    * `volume_mean`, `volume_std` – середній обсяг та станд. відхилення,
    * `volume_z` – Z-score обсягу поточного бару,
    * `daily_high`, `daily_low`, `daily_range` – показники денного діапазону,
    * тощо (можуть доповнюватися іншими полями для контексту).
  * `confidence` – попередня оцінка впевненості (у Stage1 може бути 0 для ALERT, остаточно рахується на Stage2).
  * Додатково можуть додаватися поля `hints` (підказки щодо стану, наприклад “Очікування даних...”), `state` (стан для UI, напр. `alert`/`normal`/`no_data`), `visible` (чи показувати актив на дашборді) та ін. для відображення в UI.

> **Приклад сирого сигналу Stage1:**
>
> ```json
> {
>   "symbol": "BTCUSDT",
>   "signal": "ALERT",
>   "trigger_reasons": ["VOLUME_SPIKE", "RSI_OVERSOLD"],
>   "stats": {
>     "current_price": 30000.5,
>     "atr": 0.0123,
>     "rsi": 25.4,
>     "volume": 123456.0,
>     "volume_mean": 45600.0,
>     "volume_std": 25000.0,
>     "volume_z": 3.1,
>     "daily_high": 30500.0,
>     "daily_low": 29500.0,
>     "daily_range": 1000.0
>   },
>   "confidence": 0.0,
>   "hints": [],
>   "state": "alert",
>   "stage2_status": "pending"
> }
> ```
>
> У цьому прикладі Stage1 позначив BTCUSDT як **ALERT** через сплеск обсягу та низький RSI. Докладні метрики передаються для подальшого аналізу Stage2.

* **Анти-спам і обмеження частоти:** Stage1 може містити лічильники, щоб не генерувати надто часті повторні ALERT для одного активу. Наприклад, поле `min_reasons_for_alert=2` визначає, що потрібні **як мінімум 2 різні причини**, щоб сигнал вважався ALERT (підвищує поріг важливості).
* **Кеш конфігурацій активів:** При ініціалізації `AssetMonitorStage1` завантажує для кожного символу індивідуальні калібровані пороги із Redis (через `load_thresholds`). Ці пороги (структура `Thresholds` з файлу `app/thresholds.py`) містять значення `low_gate`, `high_gate`, `atr_target`, `vol_z_threshold` для конкретного активу. Якщо в кеші нема записів, використовуються дефолтні значення. Таким чином Stage1 *динамічно* адаптує тригери під волатильність активу (через метод `adaptive_from_atr` – наприклад, для дуже волатильних монет `vol_z_threshold` може автоматично знизитися з 3.0 до 2.0).

### Stage2 – Розширений аналіз, сценарії та рекомендації

Stage2 виконує **поглиблену обробку сигналу** (переважно для випадків ALERT) та видає підсумкову торгову рекомендацію. Його компоненти:

* **Калібрування параметрів:** Перед аналізом Stage2 отримує **калібровані параметри** для даного символу. Це виконує метод `_get_calibrated_params(symbol)` – він звертається до модуля калібрування (черги CalibrationQueue, детально нижче) і витягує оптимальні пороги та налаштування індикаторів для цього активу. Калібровані параметри містять, наприклад, оптимальні пороги RSI, ATR, волатильності, коефіцієнти для розрахунку впевненості тощо. Якщо дані ще не готові, можуть використовуватись дефолтні значення (з позначкою `is_default=True`).
* **Застосування калібрування:** Всі обчислення Stage1 коригуються відповідно до каліброваних параметрів. Наприклад, поріг сплеску обсягу може бути підлаштований під середній обсяг цього активу; граничні значення RSI – під історичні характеристики тощо. Це відбувається в `_apply_calibration(stage1_signal, calib_params)` – на виході отримуємо **калібрований сигнал** (можливо, трохи змінені `trigger_reasons` чи метрики).
* **Аналіз ринкового контексту:** Метод `_analyze_market_context(stats, calib_params)` формує **загальну картину ринку**:

  * Визначаються **ключові рівні** підтримки та опору для активу (наприклад, найближчий значний максимум/мінімум, розраховані з історичних даних або передані Stage1 через `global_levels`).
  * Аналізується **тренд і волатильність** на вищих таймфреймах: можливо, Stage2 знає, чи актив знаходиться у висхідному тренді, чи є ознаки консолідації.
  * Розраховується **залежність від ринку (контекст)**: наприклад, кореляція з BTC чи індексом ринку (деякі пороги `max_correlation_threshold`, `context_min_correlation` з `stage2/config.py` можуть використовуватися, щоб врахувати стан всього ринку). Якщо весь ринок падає, сигнал на купівлю може знижуватися у впевненості.
  * **Meta-дані для NLP:** Деякі поля додаються в контекст для генерації описів – наприклад, `market_context["symbol"] = BTCUSDT` щоб у тексті можна було вказати назву, або інші текстові підказки.
* **Виявлення аномалій другого рівня:** На базі скоригованих метрик та ринкового контексту Stage2 виконує додатковий пошук **аномалій та патернів** через `_detect_anomalies(stats, trigger_reasons, calib_params)`. Це може включати:

  * Комплексні сценарії, коли збігаються кілька факторів (напр. і обсяг, і імпульс, і пробій рівня – тоді формується сценарій “Breakout with volume”).
  * Перевірки на **нестандартні ситуації**: наприклад, актив зростає проти падіння всього ринку (аномальна сила), або навпаки.
  * Результат – структура `anomaly_detection` (список або словник), що зазначає, які незвичні речі помічено (наприклад, `{"VOLATILITY": True, "TREND_REVERSAL": False}` тощо).
* **Оцінка впевненості сигналу:** На основі контексту та аномалій обчислюються **метрики впевненості** (`_calculate_confidence_metrics`). Використовуються вагові коефіцієнти факторів (задано в `STAGE2_CONFIG["factor_weights"]` для обсягу, RSI, MACD, тощо) та інші критерії:

  * Розраховується сумарна оцінка (composite score) сигналу, наскільки він сильний.
  * Також визначаються окремо показники ризику: наприклад, якщо у сценарії присутня “VOLATILITY” (ринок дуже волатильний), впевненість може знижуватися.
  * Метрики впевненості можуть включати числовий **коефіцієнт впевненості** (0 до 1) та допоміжні показники для прийняття рішення (скільки факторів підтверджують сигнал, чи використано дефолтні калібрування).
* **Генерація нарративу:** Особливість Stage2 – формування пояснення природною мовою. `_generate_trader_narrative(market_context, anomalies, trigger_reasons)` повертає текстовий опис ситуації, наприклад: *“BTCUSDT демонструє ознаки розвороту: різкий сплеск обсягів на локальному мінімумі та RSI піднявся з перепроданості. Це вказує на можливий відскок, однак волатильність залишається високою.”* Нарратив допомагає трейдеру зрозуміти *чому* рекомендація саме така. (Примітка: в поточній реалізації нарратив генерується на основі правил; розробники можуть інтегрувати модель GPT для більш складних пояснень, про що – нижче у Примітках для розробників).
* **Формування рекомендації:** На фінальному кроці `_generate_recommendation(market_context, confidence)` на основі всіх даних визначає **рекомендовану дію**:

  * Якщо сукупна впевненість висока і сигнал позитивний – рекомендація може бути `"BUY"` (купити/відкрити позицію).
  * Якщо сигнал присутній, але необхідно підтвердження або ситуація невизначена – `"WAIT_FOR_CONFIRMATION"` (чекати).
  * Негативні умови (низька якість сигналу, або ринок проти) дають рекомендацію `"AVOID"` (уникати) чи `"AVOID_HIGH_RISK"` (уникати через високу волатильність).
  * Для коротких сигналів (якби бот торгував шорт) могли б бути інші стани, але наразі логіка націлена на виявлення лонг-можливостей та уникання ризиків.
* **Розрахунок ризикових параметрів:** Метод `_calculate_risk_parameters(stats, market_context, calib_params)` обчислює оптимальні рівні входу/виходу для сигналу:

  * **Оптимальна зона входу** (`optimal_entry`): визначається як діапазон між поточною ціною та найближчим рівнем підтримки/опору (щоб вибрати кращу ціну входу).
  * **Take-Profit цілі** (`tp_targets`): множники ATR застосовуються до ціни, щоб запропонувати кілька рівнів тейк-профіту. Якщо в контексті знайдено значущі рівні опору, вони можуть обмежувати ці цілі (береться менша з розрахункової цілі та наступного великого рівня).
  * **Stop-Loss рівень** (`sl_level`): пропонується нижче найближчої підтримки – наприклад, рівень найближчого **immediate\_support** мінус половина ATR, але не нижче денного мінімуму. Це слугує захистом від неправильних значень (щоб SL не був вище поточної ціни тощо).
  * **Співвідношення Risk/Reward** (`risk_reward_ratio`): обчислюється відношення найпершої TP цілі до різниці між ціною входу та SL. Якщо R/R менше мінімально допустимого (напр. < 2.0), сигнал може бути менш привабливим.
* **Вихід Stage2:** Після успішної обробки Stage2 повертає повний результат у вигляді словника:

  * `symbol`: актив (дублюється для зручності).
  * `timestamp`: час генерації рекомендації (UTC-мітка ISO).
  * `market_context`: структурована інформація про ринок (ключові рівні, тренд, тощо).
  * `anomaly_detection`: знайдені аномалії/сценарії (набір прапорів або описів).
  * `confidence_metrics`: показники, пов’язані з оцінкою впевненості (наприклад, сумарна оцінка, деталі за факторами, ознака використання дефолтного калібрування).
  * `narrative`: згенерований текстовий коментар до сигналу.
  * `recommendation`: рекомендація для дії (наприклад, `"BUY"`, `"WAIT_FOR_CONFIRMATION"`, `"AVOID"`).
  * `risk_parameters`: словник з параметрами ризику:

    * `optimal_entry` – рекомендований діапазон цін входу,
    * `tp_targets` – список цілей для тейк-профіту,
    * `sl_level` – запропонований рівень стоп-лосу,
    * `risk_reward_ratio` – співвідношення ризик/прибуток для першої цілі.
  * `calibration_params`: (опціонально) параметри калібрування, використані для цього активу (може включати ознаку `is_default`, якщо ще не проводилось індивідуальне налаштування).
  * `quality_metrics`: метрики якості роботи алгоритму (наприклад, чи використовувались дефолтні калібрування, скільки разів поспіль застосовувались дефолти, час обробки тощо).
  * Якщо під час аналізу виникла помилка або некоректні дані – повертається поле `error` із описом і `recommendation` може бути `"INVALID_DATA"` чи `"SYSTEM_FAILURE"`.

> **Приклад результату Stage2 (скорочено):**
>
> ```json
> {
>   "symbol": "BTCUSDT",
>   "timestamp": "2025-07-13T13:37:00Z",
>   "market_context": {
>       "symbol": "BTCUSDT",
>       "trend": "UPTREND",
>       "key_levels": {
>           "immediate_support": 29800.0,
>           "immediate_resistance": 30500.0,
>           "next_major_level": 32000.0
>       },
>       "volatility": "HIGH"
>   },
>   "anomaly_detection": {"VOLATILITY": true, "TREND_REVERSAL": false},
>   "confidence_metrics": {"composite_score": 0.78, "factors_confirmed": 3},
>   "narrative": "BTCUSDT відскочив від підтримки 29800 після аномального сплеску обсягів...",
>   "recommendation": "BUY",
>   "risk_parameters": {
>       "optimal_entry": [29800.0, 30000.0],
>       "tp_targets": [31000.0, 31500.0],
>       "sl_level": 29000.0,
>       "risk_reward_ratio": 2.5
>   }
> }
> ```
>
> У цьому прикладі Stage2 підтвердив сигнал (кілька факторів співпали, композитна оцінка \~0.78) і дав рекомендацію **BUY**. Оптимальний вхід – поблизу підтримки \$29 800-\$30 000, TP цілі – \$31 000+ із R/R \~2.5, SL запропоновано на \$29 000 під найближчим мінімумом. Нарратив описує контекст для трейдера.

* **Паралельність Stage2:** Оскільки одночасно може бути кілька активів з сигналами, Stage2 обробляється асинхронно. У `screening_producer` використовується семафор на максимальну кількість паралельних задач Stage2 (за замовчуванням 10). Сигнали з `signal="ALERT"` поміщаються у чергу Stage2 (`stage2_input_queue`), яку споживає фоновий таск `stage2_consumer`. Цей споживач запускає для кожного сигналу `Stage2Processor.process(stage1_signal)` і отриманий результат поміщає у `output_queue` для подальшого використання (наприклад, для відкриття угод через TradeManager або для публікації в UI).
* **Валідація сигналу перед трейдом:** Після Stage2 результати можуть фільтруватися – наприклад, поле `validation_passed` у сигналу може показувати, чи пройшов він всі умови для реального трейду. Метод `open_trades(signals, trade_manager)` в `screening_producer` сортує результати за впевненістю, відбирає топ-N сигналів і відкриває угоди через `TradeLifecycleManager` (Stage3) для найбільш перспективних (порог `MIN_CONFIDENCE_TRADE` використовується, щоб відсікти низьковпевнені сигнали).

### Calibration Queue – Черга калібрування (оптимізація порогів)

**CalibrationQueue** – фоновий сервіс оптимізації, що постійно підлаштовує параметри індикаторів під кожен актив. Основні аспекти:

* **Навіщо потрібна калібрування:** Ринки різних крипто-активів мають різну волатильність, обсяги та поведінку. Жорстко задані пороги можуть не підходити для всіх. CalibrationQueue автоматично підбирає оптимальні значення порогів (ATR, volume spike threshold, RSI рівні тощо) для кожного символу, щоб сигнали були більш точними і містили менше хибних спрацьовувань.
* **CalibrationEngine:** Усередині використовується компонент `CalibrationEngine` (модуль `stage2/calibration_engine.py`). Він може застосовувати історичні дані та, наприклад, бібліотеку Optuna для пошуку оптимуму. При ініціалізації `CalibrationEngine(buffer, fetcher, redis_client, ...)` задаються:

  * `interval` – таймфрейм для калібрування (наприклад, "1m"),
  * `min_bars` – мінімальна кількість барів історії, щоб калібрування мало сенс (наприклад, 50),
  * `metric` – метрика оптимізації (наприклад, `"profit_factor"` або інша метрика якості сигналів/стратегій).
  * `redis_client` – пряме з’єднання до Redis для збереження результатів (CalibrationEngine може кешувати проміжні результати або писати в БД).
* **Постановка задач:** CalibrationQueue приймає задачі калібрування через метод `put(symbol, tf, priority, is_high_priority=False, is_urgent=False)`. Коли актив додається до списку відслідковуваних, або минув певний час, або актив позначено як ALERT, – формується завдання на калібрування. Система пріоритезує їх таким чином:

  * **Urgent (термінові) завдання:** для активів зі свіжим сигналом ALERT або критичними змінами. Вони додаються з найвищим пріоритетом (priority \~0.1) і міткою `is_urgent=True`. Черга опрацьовує їх негайно позачергово.
  * **High-priority завдання:** для важливих активів (наприклад, з дуже великим обсягом торгів, “сині фішки”) – додаються з високим пріоритетом (`is_high_priority=True`).
  * **Normal завдання:** періодичне калібрування для всіх інших активів (з середнім або зниженим пріоритетом, наприклад 0.5). Вони теж виконуються, але після urgent/high задач.
  * **Адаптивне старіння пріоритетів:** якщо актив довго не калібрувався, його завдання автоматично піднімається у черзі (пріоритет зменшується чисельно) щоб рано чи пізно виконатися.
* **Виконання завдань:** CalibrationQueue при ініціалізації запускає групу воркерів (наприклад, `start_workers(n_workers=20)` створює 20 асинхронних тасків). Кожен воркер дістає завдання з пріоритетної черги (`asyncio.PriorityQueue`) і виконує оптимізацію через `CalibrationEngine`:

  * Завантажуються історичні дані активу (з RAMBuffer або через DataFetcher, якщо потрібно догрузити з біржі).
  * Проганяється набір сценаріїв/стратегій з різними параметрами, оптимізується на обрану метрику (`profit_factor`, `win_rate`, `drawdown` – у коді `CalibrationEngine` можуть бути передбачені декілька цілей, підтримка multi-objective).
  * Використовується Optuna або власний перебір, після чого знаходяться найкращі параметри. Вони фіксуються у структурі `Thresholds` (або схожій) і зберігаються:

    * У Redis (ключ типу `thresholds:<symbol>` з TTL \~ 14 днів, через `cache.store_in_cache` або `cache.set_json`).
    * Опціонально, локально в JSON файл (у папці `optuna_runs/<symbol>.json` зберігається бест параметри для відладки).
* **Запобігання повторним невдачам (Circuit Breaker):** Якщо для якогось активу кілька спроб калібрування поспіль завершились невдало (наприклад, нестача даних, або немає стабільного рішення), CalibrationQueue вводить *circuit breaker*. В константах: `MAX_ATTEMPTS = 3`, `CIRCUIT_BREAKER_TIMEOUT = 600` сек – тобто після 3 невдалих спроб актив пропускається на 10 хвилин і нові задачі для нього тимчасово ігноруються. Це захищає від зациклень і перевантаження системи.
* **Інтеграція з AssetStateManager:** CalibrationQueue може приймати `state_manager` (встановлюється через `set_state_manager()` або при створенні). Менеджер станів отримує оновлення:

  * Коли завдання починається, `calib_status` активу виставляється в `"in_progress"`. Якщо завдання було терміновим, статус може бути `"queued_urgent"` або `"queued_high"`.
  * Після завершення калібрування для активу в `AssetStateManager.update_calibration(symbol, params)` оновлюється стан: записуються нові `calib_params`, `calib_status: "completed"`, `last_calib` час. Також пробуджується `calibration_event` для тих, хто чекає (наприклад, Stage2, що очікував завершення).
  * Якщо актив був в стані ALERT, після калібрування він **повторно перевіряється Stage2** (в `screening_producer` одразу після отримання нових порогів сигнал запускається Stage2 повторно, щоб оновити рекомендацію вже з точнішими параметрами).
* **Конфігурація калібрування:** CalibrationQueue може зчитувати конфіг з JSON (`calibration_queue.json`). Там задаються параметри черги (наприклад, `"max_concurrent"`), базові пріоритети, можливо, дефолтні значення порогів для нових активів (`defaults_dir` містить шаблонні `Thresholds` для різних класів активів). Також `AssetClassConfig` у `calibration_queue.py` визначає класи активів (spot, futures, meme, defi, nft, metaverse, ai, stable) – через списки регулярних виразів символів. Це використовується, щоб:

  * Призначати різні дефолтні параметри калібрування для кожного класу (наприклад, мем-монети можуть мати інші стартові пороги ніж stablecoins).
  * Легко масштабувати конфіг на групу активів: додавши символ, він автоматично віднесеться до певного класу і може мати свої нюанси.
* **TTL інвалідація кешу:** Після калібрування нові пороги пишуться з обмеженим часом життя (TTL). У нашій реалізації TTL = 14 днів (`CACHE_TTL_DAYS = 14`). Це означає, що приблизно раз на два тижні (або раніше, якщо є сигнал ALERT чи інші події) актив буде калібруватися заново, щоб пороги завжди враховували актуальні ринкові умови.
* **Метрики продуктивності:** Існує `MetricsCollector` (app.utils.metrics) – CalibrationQueue при кожному виконанні оновлює лічильники:

  * `queue_size` – поточна довжина черги,
  * `active_workers` – кількість зайнятих воркерів,
  * можливо, `tasks_completed`, `tasks_failed` тощо.
    Ці метрики доступні через API (див. розділ **Metrics API** нижче) і допомагають відслідковувати навантаження системи.

### Cache – SimpleCacheHandler (Redis Cache API)

Компонент **Cache** відповідає за єдину точку зберігання оперативних даних системи в Redis. `SimpleCacheHandler` інкапсулює роботу з Redis (асинхронний клієнт) і надає методи високого рівня. **Ключові можливості SimpleCacheHandler:**

* **Ініціалізація з конфігурації:** В конструктор можна передати хост і порт Redis (`host`, `port`) або використовувати клас-метод `SimpleCacheHandler.from_url("redis://...")` для повного URI (підтримується також REDIS\_URL з .env). При старті система викликає `init_system()` і створює глобальний об’єкт кешу `cache_handler`.

* **Простий namespace для ключів:** Більшість методів приймають ключ та *namespace*. Простір імен дозволяє розрізняти типи даних і уникати колізій:

  * Наприклад, пороги активів зберігаються з ключем `thresholds:<symbol>` в namespace `"global"`.
  * Список активних символів `fast_symbols` – теж глобальний namespace.
  * Можна використовувати й інші простори для сегрегації (наприклад, `"user:123"`), але за замовчуванням ми застосовуємо `"global"`.

* **Методи збереження/отримання:** Асинхронні методи:

  * `await cache_handler.store_in_cache(key, namespace, value, ttl=None, raw=False)`: зберігає задане значення в Redis. Якщо `raw=True`, значення записується як є (строка JSON, байти); інакше може бути серіалізоване (наприклад, Pydantic-модель можна перетворити в dict). Параметр `ttl` задає час життя ключа.
  * `value = await cache_handler.fetch_from_cache(key, namespace, raw=False)`: отримує значення за ключем. Якщо нічого не знайдено – повертає None. При `raw=False` метод може виконувати JSON-десеріалізацію або інші перетворення назад у Python-об’єкт.
  * Спеціалізовані методи для JSON: `await cache_handler.set_json(key, namespace, data, ttl=None)` – зберігає Python-об’єкт (список, dict) у вигляді JSON-строки під зазначеним ключем; `await cache_handler.get_json(key, namespace)` (якщо реалізовано) – дістає JSON і перетворює назад.

* **Методи для списку активів:** Система визначає **набір швидких активів** `fast_symbols` – ті, що відповідають критеріям фільтра (найбільші обсяги, волатильність тощо) і моніторяться в даний момент. Для їх підтримки є окремі методи:

  * `await cache_handler.set_fast_symbols(list_of_symbols, ttl)` – встановлює в Redis актуальний список тикерів. Реалізовано за допомогою, ймовірно, збереження JSON-списку або множини. TTL використовується, щоб час від часу список міг оновлюватись (prefilter може оновлювати кожні 10 хвилин).
  * `symbols = await cache_handler.get_fast_symbols()` – повертає список символів (розпарсивши JSON). Якщо список відсутній або протермінований – Pipeline на старті автоматично виконає prefilter, щоб його створити.

* **Інші можливі методи:**

  * `await cache_handler.publish(channel, message)` – хоча конкретної реалізації в `SimpleCacheHandler` може не бути (ми використовували пряме `redis_conn.publish`), можна розширити Handler для Pub/Sub.
  * `await cache_handler.delete(key, namespace)` – видалення ключів (щоб вручну очищати, напр. при перезапуску).
  * `await cache_handler.keys(pattern)` – отримання списку ключів (в debug-цілях).
  * Важливо: усі виклики до Redis у системі зроблені **асинхронними** (через `redis.asyncio`). Це дозволяє не блокувати цикл подій, навіть якщо звернення до кешу тривають кілька мілісекунд.

* **Приклади використання Cache API:**
  *Збереження каліброваних порогів:*

  ```python
  thr = Thresholds(low_gate=0.004, high_gate=0.012, atr_target=0.5, vol_z_threshold=2.5)
  payload = json.dumps(asdict(thr), ensure_ascii=False)
  await cache_handler.store_in_cache(f"thresholds:{symbol}", "global", payload, ttl=timedelta(days=14), raw=True)
  ```

  Це зберігає в Redis JSON-строку з порогами для активу, яка буде дійсна 14 днів. Інший код робить те саме через `set_json`:

  ```python
  await cache_handler.set_json("asset_state", "global", all_assets_state, ttl=30)
  ```

  Тут стан усіх активів (список словників) зберігається під ключем `asset_state:global` строкою JSON на 30 секунд (тобто UI буде брати його для початкового рендеру і він не встигне застаріти).

* **Взаємодія з іншими компонентами:** Більшість модулів отримують `cache_handler` як параметр, щоб користуватися спільним кешем. Наприклад, `AssetMonitorStage1(cache_handler=cache, ...)` зберігає у кеші пороги, `screening_producer` через `cache_handler.get_fast_symbols()` оновлює список активів, CalibrationQueue теж тримає посилання на `cache` для запису результатів. Це сприяє тому, що *всі частини системи завжди синхронізовані через Redis*, і навіть при рестарті процесу можна швидко відновити стан (пороги, список активів, історію сигналів і т.д. можна завантажити з Redis, якщо вони ще не протермінувалися).

### UI Consumer – відображення сигналів та статистики

**UI Consumer** модуль відповідає за візуалізацію та доведення сигналів до кінцевого користувача (розробника чи трейдера). На даний момент реалізовано консольний інтерфейс на базі текстових таблиць, але архітектура передбачає можливість доповнення веб-інтерфейсом через FastAPI. Основні моменти:

* **Режим роботи:** `UI_Consumer.ui_consumer(redis_url, channel="signals")` – це асинхронна корутина, яка підключається до Redis Pub/Sub каналу і оновлює таблицю сигналів у реальному часі. Запуск UI відбувається паралельно з основним пайплайном.
  У файлі `app/main.py` є функція `launch_ui_consumer()`, яка при старті відкриває новий термінал і запускає модуль UI (щоб винести таблицю в окреме вікно). На Windows це робиться через `subprocess.Popen("start cmd /k python -m UI.ui_consumer_entry", shell=True)`, на Linux – через gnome-terminal. Таким чином **UI працює окремим процесом**, спілкуючись з основним ботом через Redis.
* **Початкове завантаження даних:** Після підключення до Redis, UI Consumer робить одноразовий запит до ключа `asset_state:global`, щоб отримати поточний стан усіх активів. Цей ключ оновлюється процесом `screening_producer` кожні кілька секунд (30 с) через `cache_handler.set_json("asset_state", "global", ...)` та паралельно видається повідомлення в канал `asset_state_update`. У актуальній версії UI Consumer налаштований на канал `"signals"`, але можна переключити на `"asset_state_update"` – за потреби (механізм Pub/Sub гнучкий).
* **Live-оновлення таблиці:** Після початкового рендеру UI підписується на канал Redis (за замовчуванням `signals`). Коли надходить нове повідомлення (у вигляді JSON зі списком сигналів або окремим сигналом), UI оновлює таблицю:

  * Збирає всі отримані повідомлення пачкою (дебаунс \~0.25 с, щоб не мерехтіло надто часто).
  * Парсить JSON і викликає `_build_signal_table(results)` для побудови таблиці Rich.Table.
  * В таблиці кожен рядок – окремий актив. Колонки включають: **Symbol**, **Signal** (стан сигналу: NONE/NORMAL/ALERT), **Confidence** (впевненість або індикаторний рейтинг), **Price** (поточна ціна), **ATR**, **Volume**, **RSI**, **TP** (ціль), **SL**, **State** (статус Stage2 обробки), тощо. Значення, яких нема (None або 0) відображаються як “-”.
  * Рядки сигналів ALERT можуть підсвічуватися кольором, а якщо для активу йде **термінове калібрування**, UI\_Consumer в методі `update_asset_state_for_ui` ставить полю `status = "urgent_calibration"` і додає `hint = "Термінове калібрування для ALERT"`. Це дозволяє візуально позначити, що по цьому активу триває інтенсивний перерахунок параметрів.
  * Використовується режим Live з `rich.live.Live`, тому оновлення відбуваються прямо в консолі, без перемальовування вручну (таблиця оновлюється атомарно раз на `refresh_rate` сек, за замовчуванням щосекунди).
* **Взаємодія з FastAPI:** У проекті передбачено FastAPI додаток (`app = FastAPI()`) – можливо, для **веб-інтерфейсу** в майбутньому. Підключено StaticFiles, що вказують на папку `static` (можливо, там фронтенд веб-додатку). Також реалізовано тестовий ендпойнт `/metrics`, який повертає метрики CalibrationQueue (лічильники) – його можна викликати GET-запитом, якщо запустити додаток через uvicorn. Наразі запуск FastAPI-сервера не інтегровано у `run_pipeline()` (відсутній `uvicorn.run()`), тому якщо потрібен веб-інтерфейс, слід запускати `uvicorn app.main:app` і впевнитись, що `run_pipeline()` викликається на старт (можна додати у FastAPI event startup).
* **Telegram та інші канали:** Серед змінних середовища є `TELEGRAM_TOKEN` та `ADMIN_ID`. Це свідчить, що бот може надсилати повідомлення в Telegram (наприклад, кожен сигнал ALERT або зведення). У поточному README UI Consumer фокусується на консольному відображенні. Інтеграція з Telegram не детальна тут, але за наявності токена та admin\_id, можна передбачити: при виникненні ALERT Stage2 може надсилати короткий текстовий сигнал адміністратору (для цього в коді мав би бути модуль Telegram бот-API). Розробник, який впроваджує це, повинен додати відповідні виклики (наприклад, в момент генерації рекомендації). Документація .env (див. нижче) пояснює ці поля.

## Вхідні та вихідні дані (ключі)

Архітектура AiOne\_t побудована так, щоб компоненти обмінювалися структурованими даними через чітко визначені ключі в словниках Python. Новому розробнику важливо розуміти формат цих даних, щоб інтегрувати свої рішення або використовувати модулі системи окремо. Нижче узагальнено основні **вхідні параметри** і **вихідні поля** ключових функцій:

* **Вхідні дані (Input) до аналітичних модулів:**

  * `symbol` – (str) тикер активу, для якого проводиться аналіз. Напр., `"BTCUSDT"`. Використовується Stage1, Stage2 і всіма допоміжними функціями як ідентифікатор.
  * `df` – (pandas.DataFrame) табличка з історичними ціновими даними активу за потрібний період. Зазвичай це останні *N* свічок таймфрейму (N задається параметром `lookback`, напр. 50 барів 1-хвилинних). DataFrame повинен містити колонки стандартних цінових рядів: `open, high, low, close, volume` (та, опціонально, `timestamp`). **Примітка:** перед обробкою DataFrame проходить через `ensure_timestamp_column`, що гарантує наявність `timestamp` у мілісекундах.
  * `stats` – (dict) агреговані статистичні показники по активу. Для Stage1 це формується на місці (див. вище, `update_statistics` повертає словник зі значеннями ATR, RSI, обсягів тощо). Для Stage2 очікується, що `stage1_signal["stats"]` буде передано як частина сигналу. Цей словник використовується як основа для розширеного аналізу (щоб уникнути повторного обчислення індикаторів).
  * **Інші входи:**

    * `trigger_reasons` – список тригерів, що спрацювали (вихід Stage1, але є вхід для Stage2).
    * `calib_params` – калібровані параметри (внутрішньо добуваються Stage2 з CalibrationQueue, розробник може при інтеграції самостійно вказати їх, якщо хоче викликати Stage2Processor вручну).
    * `reference_symbol` – базовий символ для контексту (за замовчанням "BTCUSDT"): використовується у Screening Producer, щоб додатково перевіряти наявність даних по біткоїну для оцінки ринкового фону.
    * `assets` – список символів, що аналізуються пакетом (для функцій типу `screening_producer` або `process_asset_batch`).

* **Вихідні дані (Output) основних модулів:**

  * `signal` – (str) код сигналу:

    * `"NONE"` – немає сигналу (актив у спокійному стані або даних мало).
    * `"NORMAL"` – присутні деякі тригери, але ситуація не критична.
    * `"ALERT"` – зафіксована суттєва аномалія, яка потребує уваги (перевірки Stage2).
    * В контексті Stage2 `signal` зазвичай успадковується зі Stage1 (тобто Stage2 обробляє ALERT, але фінальний сигнал може залишитись ALERT або перетворитись на підтверджений торговий сигнал).
  * `recommendation` – (str) рекомендація дії, сформована Stage2:

    * `"BUY"` / `"LONG"` – сигнал на відкриття довгої позиції (покупки).
    * `"WAIT_FOR_CONFIRMATION"` – сигнал є, але бажано зачекати додаткових підтверджень.
    * `"AVOID"` – не рекомендується входити (сигнал слабкий або негативний).
    * `"AVOID_HIGH_RISK"` – уникати через підвищений ризик (висока волатильність чи невизначеність).
    * `"SELL"` / `"SHORT"` – (потенційно, якщо б отрабатывались шорт-сигнали; наразі не реалізовано).
    * `"INVALID_DATA"` – якщо Stage2 отримав некоректні дані на вхід.
    * `"SYSTEM_FAILURE"` – якщо сталася непередбачена помилка.
  * `risk_parameters` – (dict) рекомендації по управлінню ризиком для цього сигналу:

    * `optimal_entry` – \[float, float] бажаний діапазон цін входу (нижня та верхня межа). Може збігатися майже з поточною ціною або бути трохи нижче/вище залежно від ситуації.
    * `tp_targets` – список цільових рівнів Take Profit (float). Зазвичай 2-3 значення, обчислені за ATR.
    * `sl_level` – рівень Stop Loss (float).
    * `risk_reward_ratio` – (float) співвідношення прибуток/ризик для першої цілі (чим вище, тим кращий потенціал угоди; <1 – поганий сигнал).
  * `narrative` – (str) текстовий опис сигналу людською мовою. Як правило 1-3 речення, що пояснюють, що відбувається з активом і чому така рекомендація. Може включати назви тригерів у зрозумілій формі, рівні цін, настрої ринку.
  * `status` – (str) загальний статус обробки сигналу або стан активу:

    * Наприклад, у AssetStateManager поле `state` використовується для UI: `"alert"` якщо сигнал ALERT активний, `"normal"` якщо все спокійно, `"no_trade"` якщо сигналу немає.
    * `stage2_status` може бути `"pending"`, `"processing"`, `"completed"`, `"skipped"` (якщо Stage2 не запускали для NORMAL сигналу) або `"error"`.
    * `calib_status` – стан калібрування: `"pending"`, `"queued"`, `"in_progress"`, `"completed"`, `"expired"` (якщо поріг протермінувався і треба оновити) або `"error"`.
    * В контексті вихідного повідомлення користувачу, **status** можна розуміти як сукупний стан сигналу (наприклад, “alert\_confirmed”, “alert\_no\_trade”, “normal” тощо). В поточному форматі UI це поле не виводиться явно, але логіка присутня.
  * **Додаткові поля виходу:**

    * `trigger_reasons` – (List\[str]) причини сигналу (список тригерів) – дублюються зі Stage1 для розуміння ситуації.
    * `confidence` або `confidence_metrics` – показники впевненості (див. вище). У спрощеному вигляді може бути float `confidence` 0-1.
    * `market_context` / `context_metadata` – структурована інформація про ринок, корисна для девелоперів або UI, щоб в деталях показати, які рівні підтримки/опору враховано, яка волатильність (напр. context\_metadata може містити `"volatility": "HIGH", "correlation_with_btc": 0.8` і т.п.).
    * `hints` – (List\[str]) текстові підказки чи нотатки щодо стану. Наприклад, `"Очікування даних..."`, `"Недостатньо історії для повного аналізу"` або `"Calibration updated"`. Використовуються здебільшого для UI.
    * `error` – (str) повідомлення про помилку, якщо сталось (`status` тоді зазвичай `"error"`).
    * `calib_params` – (dict) значення параметрів, підібраних калібруванням (корисно для журналювання або debug).
    * `quality_metrics` – (dict) дані про якість/технічні моменти (наприклад, скільки разів поспіль застосовувалися дефолтні калібрування, скільки часу зайняла обробка сигналу, і т.д.).

**Резюме:** Stage1 приймає **символ + стрім дані** –> видає початковий `signal` + базові `stats`. Stage2 приймає **символ + stats + тригери** –> видає фінальний `signal` (або рекомендацію) + `narrative` + `risk_parameters` + інші деталі. Калібрування працює у фоні, прозоро оновлюючи `stats`/пороги в Redis, тож Stage1/Stage2 автоматично їх враховують при наступних ітераціях.

## Конфігурація: файли та змінні середовища

Перед запуском AiOne\_t необхідно налаштувати конфігураційні файли і змінні оточення (.env). Вони містять як *чутливі дані* (ключі API), так і технічні параметри системи. Пояснення кожного параметра:

### Змінні .env (файл .env в корені проєкту)

* **`REDIS_HOST`** – хост Redis-сервера. За замовчанням `localhost`. Якщо використовується Docker або віддалений Redis – вкажіть його адресу.
* **`REDIS_PORT`** – порт Redis. Стандартно `6379`.
* **`REDIS_URL`** – (опціонально) повний URL підключення до Redis, наприклад: `redis://user:pass@host:port/db`. Якщо задано `REDIS_URL`, то `REDIS_HOST/PORT` ігноруються. Це зручно для хмарних розгортань (Heroku та ін.), де Redis URL надається як одна змінна.
* **`BINANCE_API_KEY`** – API-ключ Binance для доступу до даних торгів (і потенційно для виконання угод). Потрібен режим *Read* як мінімум. Якщо ви не плануєте реальні торги – можна залишити значення `"your_default_binance_api_key"` (але тоді деякі компоненти, як `OptimizedDataFetcher`, можуть не працювати або використовувати публічні ендпоінти).
* **`BINANCE_SECRET_KEY`** – Секретний ключ API Binance. Використовується разом з API\_KEY. За замовчанням `"your_default_binance_secret_key"`.
* **`TELEGRAM_TOKEN`** – Токен Telegram-бота, через якого надсилатимуться повідомлення про сигнали. Формат: `123456789:ABC-DefGh...`. Якщо не використовуєте Telegram-інтеграцію, можна залишити дефолт або пустим.
* **`ADMIN_ID`** – Числовий ідентифікатор (ID) Telegram-користувача або чату, куди бот надсилатиме повідомлення. Отримати свій ID можна через @userinfobot. За замовчанням `0` (некоректний ID, тобто функціонал не працюватиме).
* *(За потреби можуть додаватися)*: **`LOG_LEVEL`**, **`ENV`** (щоб перемикати конфігурації, наприклад на продакшн/тест) – в поточній реалізації не використані явно, але можна додати для розширення. **Примітка:** Переконайтеся, що файл `.env` захищений і **НЕ зберігайте справжні ключі API в публічному репозиторії**.

### Конфігураційні файли

* **`stage2/config.py`** – містить словник `STAGE2_CONFIG` з численними порогами та вагами для розширеного аналізу Stage2. Розробник може відредагувати ці значення для зміни поведінки рекомендацій. Основні параметри:

  * `volume_z_threshold`: float – поріг Z-score обсягу для сплеску (наприклад, `1.2` відповідає 1.2 сигма).
  * `rsi_oversold`, `rsi_overbought`: float – рівні RSI, нижче/вище яких ринок вважається перепроданим/перекупленим (дефолт 30 і 70).
  * `stoch_oversold`, `stoch_overbought`: пороги стохастичного осцилятора %K (20 і 80).
  * `macd_threshold`: float – мінімальне значення гістограми MACD для врахування як сигналу (0.02 умовно).
  * `ema_cross_threshold`: float – чутливість перетину EMA (0.005, тобто 0.5% від ціни – мінімальна різниця між швидкою і повільною EMA, щоб вважати кросовер значущим).
  * `vwap_threshold`: float – допустиме відхилення ціни від VWAP (0.001 = 0.1%).
  * `min_volume_usd`: float – мінімальний деномінований в USD обсяг, щоб сигнал взагалі розглядати (деф. 10000). Якщо монета має обіги менші за \$10k – може ігноруватися як неактивна.
  * `min_atr_percent`: float – мінімальна відносна волатильність (ATR/Price, 0.002 = 0.2%) для врахування активу. Тихі монети теж можуть відфільтровуватись.
  * `exclude_hours`: List\[int] – години доби (за UTC), коли торги низькоактивні і сигнали слід ігнорувати або не генерувати (наприклад, `[0,1,2,3]` – з півночі до 3:00 ночі).
  * `cooldown_period`: int – період в секундах, протягом якого повторний сигнал по тому ж активу не генерується після ALERT (щоб уникнути спаму, деф. 300 сек = 5 хв).
  * `max_correlation_threshold`: float – якщо кореляція активу з BTC перевищує 0.85, можливо, сигнал слід фільтрувати, аби не відкривати багато однакових позицій.
  * `tp_mult`, `sl_mult`: float – базові множники ATR для розрахунку TP і SL (3.0 і 1.0 відповідно). В комбінації з `min_risk_reward` (2.0) вони визначають бажаний профіль угоди (наприклад, ATR*3 прибуток на ATR*1 стоп = R/R 3.0). Якщо R/R виходить нижче 2.0, сигнал вважається сумнівним.
  * `entry_spread_percent`: float – на скільки % від поточної ціни може відрізнятися точка входу (0.05 = 5%) для визначення зони оптимального входу.
  * `factor_weights`: Dict\[str, float] – ваги факторів для підрахунку впевненості сигналу. Наведені приклади: `"volume": 0.25`, `"rsi": 0.18`, `"macd": 0.20`, `"ema_cross": 0.22`, `"stochastic": 0.15`, `"orderbook": 0.20`, `"vwap": 0.25`, `"velocity": 0.18`, `"volume_profile": 0.20`. Ці ваги сумуються (ймовірно >1.0 сумарно) і використовуються в `_calculate_confidence_metrics`.
  * `min_cluster`: int – мінімальна кількість факторів, які мають співпасти, щоб сигнал вважався **кластеризованим** (4 за замовчуванням). Наприклад, якщо ≥4 різні індикатори/тригери дають сигнал, тоді confidence буде високим.
  * `min_confidence`: float – мінімальна необхідна впевненість (0.75) для того, щоб сигнал кваліфікувався як “validation\_passed” (для потенційного відкриття угоди).
  * `context_min_correlation`: float – (0.7) якщо кореляція активу з ринком нижча за 0.7, то він розглядається окремо (низька залежність від BTC), що може збільшити унікальність сигналу.
  * `sr_window`: int – вікно для розрахунку рівнів підтримки/опору (50 барів).
  * `tp_buffer_eps`: float – невеликий буфер для цілей тейк-профіту (0.0005 = 0.05%), щоб уникнути спрацювання точно на рівні (додається до цілі або віднімається, щоб ордери спрацювали трохи раніше реального рівня).

* **`app/conf/calibration_queue.json`** – конфігурація для CalibrationQueue. У ній можна налаштувати, зокрема:

  * `max_concurrent` – максимальна кількість одночасних калібрувань (у коді є значення 15, але JSON може його перевизначити).
  * `max_priority` / `min_priority` – числові межі для пріоритетів завдань.
  * `urgency_decay` – як швидко пріоритет задачі зменшується (тобто чим довше в черзі, тим вона стає терміновішою).
  * `defaults_dir` – шлях до папки з дефолтними параметрами калібрування для різних класів активів. У `app/conf/defaults/` ймовірно зберігаються JSON-файли типу `spot.json`, `meme.json` тощо, які містять стандартні пороги Thresholds для нових активів цих категорій.
  * `optuna_timeout` – час, відведений на одну задачу оптимізації (щоб не зависало надовго).
  * **Примітка:** Якщо ви хочете тонко налаштувати, як часто калібруються активи або які саме параметри підбираються – змініть відповідні значення в цьому файлі перед запуском. CalibrationQueue завантажує його при створенні об’єкта.

* **`app/thresholds.py`** – хоча це не конфіг у форматі JSON/py, але містить *структуру даних Thresholds*, що важливо для розуміння калібрування. Клас `Thresholds` із датакласом визначає поля (low\_gate, high\_gate, atr\_target, vol\_z\_threshold) та методи:

  * `adaptive_from_atr(atr_7d)` – як розрахувати ці пороги від середнього ATR за 7 днів.
  * `save_thresholds(symbol, thr, cache)` – асинхронна функція для збереження порогів у Redis + локальний JSON-бекап.
  * `load_thresholds(symbol, cache)` – завантаження порогів із Redis (або повернення дефолтних, якщо їх немає).
  * У разі розширення набору порогів (наприклад, додавання ще якихось параметрів індикаторів) – цей файл треба оновити.

* **Логування:** Рівні логів та формат теж можна віднести до конфігурації:

  * За замовчанням, у коді використовується `logging.INFO` для більшості логерів, `logging.DEBUG` для CalibrationQueue і `main` (щоб отримувати відлагоджувальну інформацію).
  * Логер `main` форматовано через RichHandler (кольоровий, без показу шляху), CalibrationQueue має свій формат `%(asctime)s - %(name)s - %(levelname)s - %(message)s`.
  * Якщо потрібно змінити детальність логів, можна правити рівні у коді або встановити через змінну оточення (якщо додати підтримку `LOG_LEVEL`).

**Підсумок:** Налаштуйте .env (обов’язково Redis, бажано Binance ключі якщо треба актуальні дані). Перевірте `stage2/config.py` – чи підходять пороги під ваш стиль торгів. Значення за замовчанням – консервативні. CalibrationQueue.config – лишайте як є, поки не розберетесь детально, він вже оптимізований для типових випадків. Усі конфігураційні файли містять коментарі українською, що пояснюють призначення параметрів – це має допомогти зробити правильні зміни.

## Приклад запуску

Для запуску проєкту **AiOne\_t** виконайте наступні кроки:

1. **Клонування репозиторію та підготовка середовища:**

   * Переконайтеся, що у вас встановлений Python 3.9+ (рекомендується 3.10 для сумісності з `redis.asyncio` та ін.).
   * Клонуйте репозиторій: `git clone https://github.com/yourname/AiOne_t.git` (URL замінити на фактичний).
   * Перейдіть в директорію проекту: `cd AiOne_t`.
   * Створіть та активуйте віртуальне середовище:

     ```bash
     python3 -m venv venv
     source venv/bin/activate   # для Linux/Mac
     .\venv\Scripts\activate    # для Windows PowerShell
     ```
   * Встановіть залежності: `pip install -r requirements.txt`.
     *Примітка:* Файл requirements.txt має містити, зокрема, `fastapi`, `pydantic-settings`, `redis`, `aiohttp`, `optuna`, `pandas`, `rich` та інші необхідні пакети. Якщо його немає, встановіть потрібні вручну згідно з імпортами в коді.

2. **Налаштування .env:**

   * Створіть файл `.env` у корені (або перейменуйте `.env.example` в `.env`, якщо надано).
   * Заповніть значення: `REDIS_HOST`, `REDIS_PORT`, `BINANCE_API_KEY`, `BINANCE_SECRET_KEY`, `TELEGRAM_TOKEN`, `ADMIN_ID` згідно з доступними вам даними (див. попередній розділ).
   * Переконайтеся, що Redis-сервер запущений на вказаному хості/порті, і що доступ по API-ключам працює (принаймні для отримання історичних даних по REST і вебсокет підключень).

3. **Запуск Redis (якщо ще не запущено):**

   * Запустіть локальний Redis сервер. Наприклад:

     ```bash
     redis-server --port 6379
     ```

     Або, якщо ви в Docker:

     ```bash
     docker run -p 6379:6379 redis:latest
     ```
   * Перевірте, що можете підключитися: `redis-cli -h localhost -p 6379 ping` має повернути `PONG`.

4. **Запуск бота AiOne\_t:**

   * Є два способи запуску:

     * **Консольний режим** (з авто-UI): Виконайте команду:

       ```bash
       python -m app.main
       ```

       або `python app/main.py` (впевніться що `app/` в PYTHONPATH).
       Ця команда запустить асинхронний пайплайн: підключиться до біржі, ініціалізує моніторинг Stage1, CalibrationQueue, та почне виводити логи. **Одночасно** має відкритися нове вікно консолі з UI-дашбордом (для Windows) або нова вкладка терміналу (Linux). Якщо нове вікно не запустилось, перевірте:

       * Для Windows: система відкриває `cmd.exe`. Іноді безправильної конфігурації може не спрацювати. Спробуйте вручну запустити UI (наступний пункт).
       * Для Linux: використовується `gnome-terminal`. Переконайтесь, що він встановлений, або змініть команду `launch_ui_consumer()` під вашу систему (можна просто зробити `subprocess.Popen(["python3", "-m", "UI.ui_consumer_entry"], ...)` у тлі).
     * **Роздільний режим**: Запустіть бекенд і UI окремо.

       1. В одному терміналі: `python -m app.main --no-ui` (якщо реалізуєте опцію або просто ігнорувати, що не бачите UI).
       2. В іншому терміналі (після старту першого): `python -m UI.ui_consumer_entry`. Це напряму запустить UI Consumer, який почитає з Redis стан і почне рендерити таблицю.
          Цей підхід корисний, якщо `launch_ui_consumer()` не підтримує вашу ОС або ви хочете запустити UI на іншій машині, підключившись до Redis віддалено (тоді задайте `redis_url` параметром або через .env).
   * **Запуск через FastAPI/uvicorn (необов’язково):** Якщо ви бажаєте користуватися REST API (наприклад, для метрик або потенційно додати ендпоїнти управління):

     * Запустіть команду: `uvicorn app.main:app --host 0.0.0.0 --port 8000`.
     * Переконайтеся, що у функції `startup` FastAPI (якщо додасте) викликається `asyncio.create_task(run_pipeline())`, інакше веб-сервер запуститься, але бот не почне працювати.
     * Надалі можна звернутись GET `http://localhost:8000/metrics` і отримати інформацію по CalibrationQueue метрикам чи іншим (розширте за бажанням).
   * **Перевірка роботи:** після запуску основного процесу, у консолі логів ви побачите повідомлення на кшталт:

     ```
     Налаштування перевірено — OK.
     Запускаємо первинний префільтр...
     Первинний префільтр: 123 символів
     Ініціалізуємо CalibrationEngine...
     Ініціалізуємо CalibrationQueue...
     Ініціалізуємо AssetMonitorStage1...
     Ініціалізуємо UI-споживача...
     Запускаємо Screening Producer...
     🔄 Оновлено список активів: +123/-0 (загалом: 123)
     📊 Дані готові для 120/123 активів
     ...
     ✅ Опубліковано стан 123 активів
     ```

     А в UI-вікні з’явиться таблиця зі списком цих активів. Спершу в полі Signal у всіх буде NONE або NORMAL, confidence \~0. Постепово, якщо знайдуться аномалії, деякі рядки стануть ALERT (підсвічені). Через декілька секунд з’являться рекомендації (BUY/WAIT/AVOID) у колонці Recommendation, TP/SL заповняться, Stage2 статус зміниться на completed.

5. **Завершення роботи:** Щоб зупинити бота, натисніть `Ctrl+C` у терміналі основного процесу. Це зупинить asyncio event loop. UI процес можна закрити окремо (закрити вікно або Ctrl+C якщо запущено вручну). При коректному завершенні сесії AIone\_t закриє підключення до біржі та Redis, а також файл сесію aiohttp.

6. **Налагодження та тестовий режим:** Якщо ви бажаєте протестувати систему без підключення до біржі:

   * Можна задати `use_manual_list = True` у `run_pipeline()` і вписати власний список `fast_symbols` (наприклад, декілька тикерів). Тоді префільтр пропуститься, а система працюватиме з цими активами.
   * Після цього ви можете штучно нагодувати `RAMBuffer` даними (вставивши CSV історію або генеруючи випадкові дані) та дивитись, як реагує Stage1/Stage2.
   * Також можна викликати окремо `monitor.check_anomalies(symbol, df)` для вашого DataFrame або `Stage2Processor.process(stage1_signal)` з вручну складеним сигналом, щоб перевірити роботу конкретних частин (див. розділ **Примітки для розробників** для деталей).

## Структура директорій

Проєкт має модульну структуру. Нижче наведено спрощену структуру каталогів і файлів з поясненнями:

```
AiOne_t/                     # Корінь проекту (репозиторій)
├─ app/                      # Основний пакет додатку
│   ├─ main.py               # Головний модуль запуску (pipeline, FastAPI app)
│   ├─ settings.py           # Завантаження .env конфігурації (BaseSettings)
│   ├─ thresholds.py         # Клас Thresholds та функції збереження/завантаження порогів
│   ├─ screening_producer.py # Основний цикл моніторингу та координації Stage1->Stage2->Trade
│   ├─ calibration_queue.py  # Реалізація класу CalibrationQueue та супутніх структур
│   └─ utils/                # Утиліти додатку
│       └─ metrics.py        # Модуль збору метрик (лічильники для калібрування, черги тощо)
├─ data/                     # Модулі роботи з даними (каш, історичні дані, підключення)
│   ├─ cache_handler.py      # Клас SimpleCacheHandler (обгортка над Redis)
│   ├─ raw_data.py           # Модуль завантаження історичних даних (REST API біржі)
│   ├─ file_manager.py       # Клас для керування файлами (збереження даних, якщо потрібно)
│   ├─ ws_worker.py          # WebSocket Worker – отримує потік ринкових даних (1m свічки)
│   └─ ram_buffer.py         # Буфер в пам'яті для збереження отриманих барів (історія кожного символу)
├─ stage1/                   # Пакет Stage1 – швидкий моніторинг і тригери
│   ├─ asset_monitoring.py   # Клас AssetMonitorStage1 з реалізацією аналізу потокових даних
│   ├─ asset_triggers.py     # Окремі функції-тригери Stage1 (визначення сплеску обсягу, волатильності, RSI дивергенції тощо)
│   ├─ indicators.py         # Допоміжні класи для індикаторів (RSIManager, ATRManager, VWAPManager, VolumeZManager, тощо)
│   └─ utils.py              # Утиліти Stage1 (наприклад, форматування обсягів, open interest для UI)
├─ stage2/                   # Пакет Stage2 – розширений аналіз
│   ├─ market_analysis.py    # Клас Stage2Processor та функція stage2_consumer (обробка сигналів Stage1, формування рекомендацій)
│   ├─ calibration_engine.py # Клас CalibrationEngine – логіка оптимізації порогів (пошук по історичних даних)
│   ├─ config.py             # Конфігурація Stage2 (пороги, ваги факторів, інші параметри)
│   └─ (можливо інші модулі) # Напр. scenario.py – бібліотека шаблонів сценаріїв, не представлено тут, але може бути
├─ stage3/                   # Пакет Stage3 – менеджер угод (торгівля)
│   ├─ trade_manager.py      # Клас TradeLifecycleManager – відкриття/супровід/закриття угод, логування P&L
│   └─ (можливо trade_strategies.py) # Набори стратегій або правил управління угодою
├─ UI/                       # Пакет користувацького інтерфейсу
│   ├─ ui_consumer.py        # Клас UI_Consumer – рендер консольної таблиці, підписка на канал Redis
│   ├─ ui_consumer_entry.py  # Точка входу UI – створює і запускає UI_Consumer (asyncio)
│   └─ (компоненти веб-UI)   # Можливо, файли для фронтенду, якщо планується (напр. streamlit_app.py або шаблони)
├─ static/                   # Статичні файли для веб-інтерфейсу (якщо використовувати FastAPI для UI)
│   └─ index.html            # Пример: веб-додаток, який підключається до WebSocket або відображає метрики
├─ storage/                  # Директорія для файлів зберігання (бази даних, записи калібрування)
│   ├─ optuna.db             # SQLite база Optuna для збереження історії досліджень калібрування (шлях в OPTUNA_SQLITE_URI)
│   ├─ thresholds_history.db # (необов’язково) SQLite історія порогів (якщо увімкнути запис, в коді зараз викл.)
│   └─ optuna_runs/          # JSON файли з параметрами кращих порогів для кожного символу (резервне копіювання)
├─ tests/                    # Тести (якщо наявні)
│   └─ ...                   # Юніт-тести для модулів Stage1, Stage2, Calibration, Cache
└─ requirements.txt          # Список залежностей проекту
```

*(Структура може незначно відрізнятися залежно від версії проєкту. Наприклад, пакети можуть бути об’єднані під спільним неймспейсом `ai_one_t/` тощо. Важливо слідкувати, щоб імпорт шляхів відповідав фактичній структурі – див. імпорти на початку файлів.)*

## Примітки для розробників та інтеграції

Цей розділ надає додаткову інформацію для розробників, які планують модифікувати AiOne\_t, використовувати його компоненти у власних системах або навіть інтегрувати з AI-моделями (GPT) для розширення функціоналу:

* **Використання модулів автономно:** Завдяки модульній архітектурі, ви можете застосовувати частини системи окремо:

  * *Stage1 як окрема бібліотека:* Ви можете імпортувати `AssetMonitorStage1` у свій код і використовувати його методи. Наприклад, якщо у вас є підготований DataFrame `df` для символу, можна викликати:

    ```python
    monitor = AssetMonitorStage1(cache_handler=cache)
    signal = await monitor.check_anomalies("ETHUSDT", df)
    print(signal)  # словник сигналу Stage1
    ```

    Це поверне структуру аналогічну описаній раніше (signal, trigger\_reasons, stats тощо) для поточного стану `df`. Переконайтесь, що перед цим ви ініціалізували `cache_handler` (для порогів) та, по бажанню, завантажили глобальні рівні через `monitor.set_global_levels(daily_data)`.
  * *Stage2 у власному сценарії:* Можливий сценарій – ви отримали сигнал ALERT (можливо, своїм способом) і хочете скористатись Stage2Processor, щоб оцінити його. Це можна зробити так:

    ```python
    from stage2.market_analysis import Stage2Processor
    processor = Stage2Processor(calib_queue=my_calib_queue)  # передайте робочу CalibrationQueue
    result = await processor.process(stage1_signal_dict)
    ```

    `stage1_signal_dict` повинен містити хоча б `'symbol'`, `'stats'` та `'trigger_reasons'` (як описано в розділі Input). На виході `result` отримаєте повний аналіз (recommendation, narrative, risk\_parameters...). Якщо у вас немає запущеної CalibrationQueue, можна все одно викликати Stage2Processor, але тоді він, ймовірно, використовує дефолтні пороги (що може трохи знизити якість результату).
  * *Cache API інтеграція:* SimpleCacheHandler – універсальний. Ви можете використати його у своєму коді для кешування будь-чого. Наприклад, збереження власних даних або спільного стану:

    ```python
    cache = SimpleCacheHandler(host="localhost", port=6379)
    await cache.set_json("myservice", "global", {"status": "running"}, ttl=60)
    status = await cache.get_json("myservice", "global")
    ```

    Це, фактично, буде працювати як простий конфіг-сервер або розшарене сховище між процесами. Будьте уважні з вибором ключів і namespace, щоб не перетнутися з ключами AiOne\_t. Наприклад, всі ключі системи починаються з певних слів (`thresholds:`, `asset_state`, `fast_symbols` і т.д.), тож уникайте їх у своїх.
  * *TradeLifecycleManager:* Якщо ви хочете симулювати/розширити торгівлю – цей компонент (Stage3) можна замінити або інтегрувати зі справжнім API біржі. За замовчанням `open_trade` у ньому, ймовірно, просто логує відкриття або додає у внутрішній список. Ви можете підключити реальний Binance SDK або свій торговий рушій для виконання угод, реагуючи на вихід Stage2.

* **Робота з GPT/NLP:** AiOne\_t вже генерує текстові нарративи на основі правил. Якщо ви плануєте інтегрувати більш просунуту AI-модель (GPT-3.5, GPT-4) для аналізу чи генерації описів:

  * Можна на етапі `_generate_trader_narrative` викликати зовнішній сервіс: наприклад, сформувати prompt з `market_context` і `anomalies` та відправити до OpenAI API. Отриманий результат вставити як narrative. Це потребуватиме наявності API ключа OpenAI і відповідного пакету (`openai`).
  * Зважайте на продуктивність: виклик моделі GPT – це мережевий запит, що може тривати сотні мілісекунд або кілька секунд. Якщо ви додаєте це синхронно в Stage2, то затримаєте весь потік сигналів. Краще реалізувати **асинхронний пул** або окрему чергу для NLP: відправляти попередній шаблон нарративу відразу користувачу, а GPT-відповідь надіслати пізніше як оновлення (через той же Redis канал, наприклад, у `context_metadata`).
  * Ще одна можливість – використовувати GPT **для калібрування**: на даний момент калібрування базується на оптимізації чисел. Теоретично, можна було б застосувати ML/AI для прогнозування оптимальних параметрів на основі історичних даних. Але це виходить за межі поточної реалізації. Проте, якщо у вас є напрацювання, модуль CalibrationEngine можна розширити або замінити. Головне – дотримати контракт: метод має повертати структуру параметрів, яку розуміє Stage2Processor.

* **Розширення тригерів та факторів:** Архітектура дозволяє легко додавати нові тригери Stage1 і відповідно нові фактори Stage2:

  * Щоб додати тригер Stage1: створіть функцію, що приймає `symbol` і DataFrame, і повертає булеве значення чи метрику. Додайте її виклик у `AssetMonitorStage1.check_anomalies` (наприклад, аналогічно до існуючих). Також додайте опис у docstring класу. Не забудьте врахувати цей тригер у Stage2 (наприклад, додайте фактор у `factor_weights` і врахуйте при побудові narrative).
  * Для нового фактора Stage2, який не прямо з Stage1: модифікуйте `_analyze_market_context` або `_detect_anomalies`, щоб він додавав у `anomalies` чи `market_context` потрібну інформацію. Потім відкоригуйте `_calculate_confidence_metrics`, щоб використати це (наприклад, якщо ви додаєте фактор «відкритий інтерес» – можна додати вагу і вплив на рекомендацію).

* **Безпека та відмовостійкість:** З огляду на активну розробку, важливо врахувати моменти:

  * Перевірка вхідних даних: Stage2 виконує `_validate_input(stats)` перед аналізом, це гарантує, що всі потрібні поля є і мають сенс. Якщо ви передаєте свої дані, стежте за цим.
  * Обробка виключень: Кожен рівень стадій загортає роботу в try/except. Якщо щось піде не так, сигнал не призведе до краху всього бота – він позначиться `error` і піде далі. Розробникам слід логувати такі помилки і відлагоджувати, але у продакшні бот продовжить працювати зі іншими активами.
  * Перезапуск та відновлення: Завдяки Redis, при перезапуску більшість важливого стану зберігається (список fast\_symbols, пороги, останні сигнали). Тим не менш, **при рестарті** CalibrationQueue починає спочатку (поточні задачі пропадають), а WSWorker знову завантажить історію 50 барів і почне моніторинг. Це нормально, але врахуйте, що у перші кілька хвилин після рестарту сигнали можуть бути не максимально точними, поки не оновляться калібрування.
  * **Active Development Warning:** Оскільки статус **активна розробка**, API може змінюватися. Уточнюйте версію документації та коду. Рекомендується писати юніт-тести на ваші інтеграції (особливо, якщо ви використовуєте AiOne\_t як залежність), щоб вчасно виявити, якщо, наприклад, формат `risk_parameters` змінився або `UI_Consumer` почав слухати інший канал.

* **Спільна робота з GPT (для розробників-документаторів):** Цей README сам значною мірою згенерований та вдосконалений за допомогою GPT-4. Якщо ви, як розробник, використовуєте ChatGPT для генерації коду чи документів:

  * Обов’язково перевіряйте згенерований код на відповідність проектним вимогам і безпечність (GPT може щось пропустити).
  * Використовуйте docstring-и в коді (які вже є двомовні коментарі) – вони допоможуть як живим розробникам, так і моделям ШІ зрозуміти контекст при подальшому автодоповненні.
  * Інтегруючи модель у runtime (для нарративів чи прогнозів) – слідкуйте за витратами токенів і встановлюйте ліміти, щоб бот не зависав на очікуванні відповіді від AI під час швидкого ринкового руху.

## Статус розробки: *активна розробка*

AiOne\_t наразі **знаходиться на стадії активної розробки**. Це означає:

* Кодова база регулярно оновлюється, додаються нові функції, виправляються баги. Структура, описана вище, актуальна на даний момент, але може еволюціонувати.
* Не всі заплановані компоненти реалізовані на 100%. Зокрема, веб-інтерфейс FastAPI може бути розширений, інтеграція з реальними торгами (через Binance API) – в тестовому режимі.
* Проєкт поки що **не рекомендується для використання на реальних біржах з коштами**, якщо ви не впевнені у його стабільності. Потрібно провести більше тестувань (як симуляційних, так і forward-testing на демо-рахунках).
* **Контрибуції вітаються:** Якщо ви розробник, який хоче покращити AiOne\_t, сміливо створюйте pull request. Особливо цінні області – оптимізація продуктивності (бот обробляє багато даних, важливо тримати невелике споживання пам’яті і CPU), нові торгові стратегії для Stage2/Stage3, та інтеграція машинного навчання для передбачення ринку.
* **Зворотній зв’язок:** Будь-які баг-репорти або пропозиції можна направляти через Issues на GitHub. Зважаючи на активну фазу розробки, реакція може бути оперативною.

Сподіваємось, ця документація була вичерпною та зрозумілою. Новому Python-розробнику рекомендуємо почати з запуску системи на історичних даних, перегляду логів та UI, а потім поступово заглиблюватися у код Stage1, Stage2. Завдяки модульності, ви можете підміняти частини системи або використовувати її як базу для власного крипто-трейд бота, заощадивши час на реалізації основної інфраструктури. Успіхів у розробці та трейдингу!


## Контактна інформація:
Якщо у вас виникли питання або пропозиції, зв'яжіться з автором проекту за адресою:
- Email: Viktoriakievstd1@gmail.com 
Stdst07.1@gmail.com 
- GitHub: [Stanislav Std07-1](https://github.com/Std07-1)
- TG : @Std07_1 
